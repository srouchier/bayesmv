[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"website promotes use Bayesian data analysis building energy use monitoring, especially context Measurement Verification (M&V) methods.target audience book energy experts may moderate background statistics applied mathematics. One main arguments promoting Bayesian data analysis universally applicable, accessible. aim give building energy practicioners tools accurately assess savings following energy conservation measures, along uncertainty.guide assumes reader already knows core statistical concepts M&V: errors uncertainty, regression basics, model validation metrics. however emphasise terms order illustrate specifics Bayesian methods.first part website introduces reader main concepts measurement verification, Bayesian data analysis. amount theoretical background voluntarily kept short order keep focus practical examples. References included readers wish learn .second part tutorials whole-building energy monitoring M&V, referred “Option C” IPMVP documentation. series three tutorials gradually illustrate advantages Bayesian data analysis M&V:first tutorial serves introduction Stan platform, shows Bayesian analysis obtains uncertainty assessments classical methods, analytical solutions available.reader reassured accuracy method, second tutorial shows effortlessly extends complex model structures, analytical solutions may longer evaluate uncertainty analytically.third tutorial addresses issue residuals autocorrelation, often arises model calibration. show overcome issue Bayesian models.third part website still construction address IPMVP Option D -called Bayesian calibration building energy models.","code":""},{"path":"index.html","id":"the-content-and-how-to-use-it","chapter":"Welcome","heading":"The content and how to use it","text":"content displayed R notebooks allow displaying full code calculations, results explanations. order apply methods use cases, first:Install R RstudioInstall Stan. can learn Stan basics link full Stan documentation.Additionally, wish replicate results shown tutorials, may either download full book repository run R markdown files matching chapters; download data sets copy/paste code R files.use R main programming language analyses, content also adaptable environments reader may familiar : Python, Julia Matlab. mention alternatives .","code":""},{"path":"index.html","id":"about","chapter":"Welcome","heading":"About","text":"Simon Rouchier, lecturer Université Savoie Mont Blanc, Chambéry, France.website beta version future book. possibly still typos inconsistencies: welcome feedback email book’s Github repo.Ce(tte) œuvre est mise à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International.","code":""},{"path":"back-mv.html","id":"back-mv","chapter":"1 Measurement and verification","heading":"1 Measurement and verification","text":"chapter next one excerpts author’s larger website building energy statistical modelling.","code":""},{"path":"back-mv.html","id":"intro-to-mv-and-the-ipmvp","chapter":"1 Measurement and verification","heading":"1.1 Intro to M&V and the IPMVP","text":"Measurement Verification (M&V) process assessing savings caused Energy Conservation Measure (ECM). M&V crucial tool establishment Energy Performance Contracts (EPC), can established basis designed performance (building energy simulation), eventual uncertainty analysis /sensitivity analysis, basis measured energy consumption.International Performance Measurement Verification Protocol (IPMVP) formalizes process, presents several options conduct . Savings determined comparing measured consumption demand implementation program, making suitable adjustments changes conditions.example adjustment , estimating energy savings delivered ECM, substract new energy consumption consumption occurred building stayed situation weather conditions reporting period (adjusted baseline consumption). requires prediction model can extrapolate initial behaviour building accounting variable weather conditions. possible adjustments include changes occupancy schedules. necessary assess whether measured energy savings caused ECM , changes influences.\nFigure 1.1: IPMVP provides guidelines perform M&V\n“avoided energy consumption” approach, savings reported conditions reporting (post-retrofit) period. Alternatively, “normalized savings” approach, savings calculated separate set conditions, requires fitting separate models pre- post-ECM periods, comparing predictions new conditions.IPMVP presents several options, depending whether operation concerns entire facility portion, defines notion measurement boundary set measurements relevant determine savings (see Sec. 1.2 ).order verify savings single equipment, measurement boundary can drawn around , approach used retrofit-isolation: IPMVP options B.purpose reporting verify total facility energy performance, approach whole-facility option C.IPMVP option D, savings determined simulation pre-ECM energy consumption rather direct measurements. simulation model calibrated predicts energy load matches post-ECM metered data.","code":""},{"path":"back-mv.html","id":"boundaries","chapter":"1 Measurement and verification","heading":"1.2 Measurement and modelling boundaries","text":"M&V options rely definition numerical model reproduces relationship variables monitored measurement boundary.dependent variable \\(y\\), model output, variable wish fitted model able predict.explanatory variables, independent variables, model inputs try explain evolutions dependent variable. Explanatory variables denoted \\(x\\) regression models, \\(u\\) complex hierarchical models \\(x\\) may denote latent variable instead.models latent variables, unobserved affect dependent variable.IPMVP defines measurement boundaries “notional boundaries drawn around equipment, systems facilities segregate relevant saving determination . Energy Consumption Demand equipment systems within boundary must measured estimated. […] energy effects occurring beyond selected measurement boundary called interactive effects. magnitude interactive effects needs estimated evaluated determine savings associated ECMs.”definition boundaries work simulations: model must defined inputs outputs measured independent dependent variables, energy effects occurring within boundaries either fixed, part list parameters \\(\\theta\\) estimated calibration.\nFigure 1.2: Building energy models simulate interactions envelope, ambiance, HVAC systems controls, described finite set parameters. explanatory variables related two conditions mentioned earlier: weather occupants. dependent variables separate energy consumptions.\nTypical modelling boundaries building energy simulation (BES) resemble Fig. 1.2. time-varying inputs provided user weather files occupancy profiles. time, latter come standard scenarios rather measurement. Occupancy understood BES finite set actions influences: presence, temperature set-points, use appliances. model returns predictions energy use, usually higher level disaggregation (consumption system) easily available measurement.","code":""},{"path":"back-mv.html","id":"back-stats","chapter":"1 Measurement and verification","heading":"1.3 Error and uncertainty","text":"Inverse problem theory can summed science training models using measurements. target training either learn physical properties system indirect measurements, setting predictive model can reproduce past observations.general principle solving system identification problem describe observed phenomenon model allowing simulation. Measurements \\((\\mathbf{x},\\mathbf{y})\\) carried experimental setup: building probed quantities wish estimate energy performance (indoor temperature, meter readings, climate, etc.) model defined mapping measurements set input \\(\\mathbf{x}\\) (boundary conditions, weather data) output \\(\\mathbf{y}\\). numerical model mathematical formulation outputs \\(f(x, \\theta)\\), parameterised finite set variables \\(\\theta\\). intuitive way calibrate model minimize indicator sum squared residuals, order find value \\(\\theta\\) makes model closely match data.Ideally, model unbiased: accurately describes behaviour system, exists true value \\(\\theta^*\\) parameter vector model output reproduces undisturbed value observed variables.\n\\[\\begin{equation}\ny_k = f(x_k, \\theta^*) + \\varepsilon_k\n\\tag{1.1}\n\\end{equation}\\]\n\\(\\varepsilon\\) denotes measurement error, .e. difference real process observed value \\(y\\). convenient assumption additive noise, .e. \\(\\varepsilon_k\\) sequence independent identically distributed random variables.practice, \\(\\theta^*\\) never reached exactly, rather approached estimator \\(\\hat \\theta\\), entire process estimating measurements disturbed array approximations:Experimental errors. numerical data \\((x,y)\\) available model calibration differs hypothetical outcome ideal, undisturbed physical system. Sensors may intrusive, produce noisy measurements, may poorly calibrated, finite precision resolution…Numerical errors. hypothesis unbiased model (Eq. (1.1)) states exists parameter value \\(\\theta^*\\) model output separated observations \\(y\\) zero mean, Gaussian distributed measurement noise. means model perfectly reproduces physical reality, perceptible error due imperfection sensors. exceedingly optimistic, especially building energy simulation.\nFigure 1.3: Errors uncertainties parameter estimation, caused measurement modelling errors\nGuide expression Uncertainty Measurement (GUM)(JCGM (2008)) separates errors random component systematic component: systematic errors errors retain non-zero mean measurement repeated infinite number times repeatability conditions. Systematic random errors, whether concern measurement modelling procedures, affect estimation parameter \\(\\theta\\) terms accuracy precision. figure illustrates accuracy precision case estimating parameter value \\(\\theta\\), exact terminology can used purpose trained model predict future values variable \\(y\\).GUM defines uncertainty (measurement) dispersion values reasonably attributed measured quantity. Similarly, parameter estimates model predictions come uncertainty, quantifies possible range values caused random errors measurement modelling processes. Precision indicator low uncertainty, can conveyed confidence intervals.hand, accuracy measure bias. difference “true” value target variable mean estimation.Biased estimates predictions outcome errors explicitely taken account inverse problem. tend prefer low bias high uncertainty, high bias low uncertainty: indeed, high uncertainty suggests data sufficient provide confident inferences, incites caution communicating results.description bias uncertainty applies value estimated model parameters, predictions subsequently performed fitted model. particular, concerns estimation savings based energy use predictions: end goal obtain reliable (unbiased) inference energy savings uncertainty. motivation guide show Bayesian methods well suited goal.","code":""},{"path":"back-bayes.html","id":"back-bayes","chapter":"2 Bayesian data analysis","heading":"2 Bayesian data analysis","text":"chapter covers basics Bayesian inference, motivation behind choice use practice. internet lot reading material matter wish go .Gelman et al’s book Bayesian data analysis, aka Big Bayesian Book, covers every aspect vast field example-oriented.Bayesian workflow data analysis practical summary, although still comprehensive.Statistical rethinking another vast Bayesian course spanning theoretical fundamentals practical examples.Michael Betancourt’s extensive lectures range basics probability theory extremely detailed Bayesian workflow.","code":""},{"path":"back-bayes.html","id":"motivation-for-a-bayesian-mv","chapter":"2 Bayesian data analysis","heading":"2.1 Motivation for a Bayesian M&V","text":"Bayesian statistics mentioned Annex B ASHRAE Guideline 14, observed standard approaches make difficult estimate savings uncertainty complex models required measurement verification worflow:“Savings uncertainty can determined exactly energy use linear function independent variable(s). complicated models energy use, changepoint models, data serially autocorrelated errors, approximate formulas must used. approximations provide reasonable accuracy compared simulated data, general difficult determine accuracy given situation. One alternative method determining savings uncertainty desired degree accuracy use Bayesian approach.”Still topic measurement verification, estimation savings uncertainty, several advantages drawbacks Bayesian approaches described (Carstens, Xia, Yadavalli (2018)). Advantages include:Bayesian models probabilistic, uncertainty automatically exactly quantified. Confidence intervals can interpreted way people understand : degrees belief value parameter.Bayesian models universal flexible standard methods. Models also modular can designed suit problem. example, different create terms serial correlation, heteroscedasticity (non-constant variance) specify ordinary linear model.Bayesian approach allows incorporation prior information appropriate.savings need calculated “normalised conditions”, example, “typical meteorological year”, rather conditions post-retrofit monitoring period, possible quantify uncertainty using current methods. However, (Shonder Im (2012)) shown can naturally easily quantified using Bayesian approach.first two points relevant data analyst: arbitrary model structure can defined explain data, exact set formulas can used obtain uncertainty models fitted.","code":""},{"path":"back-bayes.html","id":"bayesian-inference-in-theory","chapter":"2 Bayesian data analysis","heading":"2.2 Bayesian inference in theory","text":"Bayesian model defined two components:observational model \\(p\\left(y|\\theta\\right)\\), likelihood function, describes relationship data \\(y\\) model parameters \\(\\theta\\).prior model \\(p(\\theta)\\) encodes eventual assumptions regarding model parameters, independently observed data. Specifying prior densities mandatory.target Bayesian inference estimation posterior density \\(p\\left(\\theta|y\\right)\\), .e. probability distribution parameters conditioned observed data. consequence Bayes’ rule, posterior proportional product two previous densities:\\[\\begin{equation}\np(\\theta|y) \\propto p(y|\\theta) p(\\theta)\n\\tag{2.1}\n\\end{equation}\\]formula can interpreted follows: posterior density compromise assumptions evidence brought data. prior can “strong” “weak”, reflect less confident prior knowledge. posterior stray away prior data introduced.\nFigure 2.1: Example estimating set point temperature assuming Normal prior distribution centred around 20°C. dashed line point estimate obtained data considered. posterior distribution can seen “refinement” prior, given evidence data.\ngeneral, information posterior distribution represented summary statistics mean, variance credible intervals, can used inform decisions easier interpret full posterior distribution. summary statistics take form posterior expectation values certain functions, \\(f(\\theta)\\),\\[\\begin{equation} \\label{posterior_expectation}\n    \\mathbb{E}[f(\\theta)] = \\int p(\\theta|y) f(\\theta) \\mathrm{d} \\theta\n    \\tag{2.2}\n\\end{equation}\\]sophisticated questions answered expectation values custom functions \\(f(\\theta)\\). One common example posterior predictive distribution: many applications, one interested estimating parameter values, also predictions \\(\\tilde{y}\\) observable new period. distribution \\(\\tilde{y}\\) conditioned observed data \\(y\\) called posterior predictive distribution:\\[\\begin{equation}\np\\left(\\tilde{y}|y\\right) = \\int p\\left(\\tilde{y}|\\theta\\right) p\\left(\\theta|y\\right) \\mathrm{d}\\theta\n\\tag{2.3}\n\\end{equation}\\]posterior predictive distribution average model predictions posterior distribution \\(\\theta\\). formula equivalent concept using trained model prediction.Apart possibility define prior distributions, main specificity Bayesian analysis fact variables encoded probability densities. two main results, parameter posterior \\(p(\\theta|y)\\) posterior prediction \\(p\\left(\\tilde{y}|y\\right)\\), point estimates complete distributions include full description uncertainty.","code":""},{"path":"back-bayes.html","id":"a-bayesian-data-analysis-workflow","chapter":"2 Bayesian data analysis","heading":"2.3 A Bayesian data analysis workflow","text":"section excerpt author’s larger website building energy statistical modelling.","code":""},{"path":"back-bayes.html","id":"overview","chapter":"2 Bayesian data analysis","heading":"2.3.1 Overview","text":"mentioned Sec. 1.3, inverse problems trivial. possible available data simply insufficient bring useful inferences, still try train unsuitable model . Statistical analysts need right tools guide model selection training, warn risk biased inferences predictions.chapter attempt summarize essential points Bayesian workflow building energy perspective. Frequentist inference also mentioned, particular case Bayesian inference.Gelman et al. (Gelman et al. (2013)) divide process Bayesian data analysis three steps illustrated Fig. 2.2:Setting full probability model;Conditioning observed data (learning);Evaluating fit model implications resulting posterior (checking validation).\nFigure 2.2: workflow proper specification training one model. workflow similar frequentist Bayesian inference.\n","code":""},{"path":"back-bayes.html","id":"step-1-model-specification","chapter":"2 Bayesian data analysis","heading":"2.3.2 Step 1: model specification","text":"first step building model conceptual analysis system available data. first question decide want learn data, related choice measurement modelling boundaries mentioned Sec. 1.2, choice model structure: measurements dependent variable \\(y\\), relevant explanatory variables \\(x\\), model parameters \\(\\theta\\) defined.model definition greatly impacted time resolution length dataset. Higher time resolutions (hour) enable choice dynamical models, can encode inferential information imply complex development. Longer datasets (several months) enable aggregation data longer resolutions observations covering different weather conditions.next step development model: translation conceptual narrative system formal mathematical descriptions. target formulate entire system probabilities fitting method can work . case simple regression models, observational model may summarized single likelihood function \\(p(y|\\theta)\\), eventually conditioned explanatory variables.practitioner wishes use regression model explain relationship parameters data, Bayesian framework similar usual (frequentist) framework. example, Bayesian model linear regression three parameters \\((\\theta_0,\\theta_1,\\theta_2)\\) two explanatory variables \\((X_1,X_2)\\) may read:\n\\[\\begin{align}\n    p(y|\\theta,X) & = N\\left(\\theta_0 + \\theta_1 X_1 + \\theta_2 X_2, \\sigma\\right) \\tag{2.4} \\\\\n    p(\\theta_i) & = \\Gamma(\\alpha_i, \\beta_i) \\tag{2.5}\n\\end{align}\\]means \\(y\\) follows Normal distribution whose expectation linear function \\(\\theta\\) \\(X\\), standard deviation \\(\\sigma\\) (measurement error). second equation prior model: example, parameter assigned Gamma prior distribution parameterised shape \\(\\alpha\\) scale \\(\\beta\\). model structures can formulated similarly: change-point models, polynomials, models categorical variables… Bayesian modelling however allows much flexibility:distributions Normal distribution can used observational model;Hierarchical modelling possible: parameters can assigned prior distribution parameters (hyper)prior distribution;Heteroscedasticity can encoded assuming relationship error term explanatory variables, etc.complex models latent variables separate expressions respective conditional probabilities observations \\(y\\), latent variables \\(z\\) parameters \\(\\theta\\). case, likelihood function \\(p(y,z|\\theta)\\) marginal likelihood function \\(p(y|\\theta)\\) :\n\\[\\begin{equation}\n    p(y|\\theta) = \\int p(y,z|\\theta) \\mathrm{d}z\n    \\tag{2.6}\n\\end{equation}\\]IPMVP option D relies use calibrated building energy simulation (BES) models. models described much larger number parameters equations simple regression models typically used IPMVP options. context, feasible fully describe BES models form simple likelihood function \\(p(y|\\theta)\\). order apply Bayesian uncertainty analysis BES model, possible first approximate Gaussian process (GP) model emulator. process denoted Bayesian calibration based seminal work Kennedy O’Hagan (Kennedy O’Hagan (2001)). opposed manual adjustment building energy model parameters, Bayesian calibration explicitly quantifies uncertainties calibration parameters, discrepancies model predictions observed values, well observation errors (Chong Menberg (2018)).","code":""},{"path":"back-bayes.html","id":"priorpredictivechecking","chapter":"2 Bayesian data analysis","heading":"2.3.3 Prior predictive checking","text":"full probability model formalization many assumptions regarding data-generating process. theory, model can formulated based domain expertise, regardless data. practice, model inconsistent data little chance yield informative inferences training. prior predictive distribution, marginal distribution observations \\(p(y)\\), way check consistency expertise.\\[\\begin{equation}\np\\left(y\\right) = \\int p\\left(y|\\theta\\right) p\\left(\\theta\\right) \\mathrm{d}\\theta\n\\tag{2.7}\n\\end{equation}\\]Basically, computing distribution equivalent running simulations numerical model training, assumed values parameters. Bayesian terms, first draw finite number parameter vectors \\(\\tilde{\\theta}^{(m)}\\) prior distribution, use compute model output \\(\\tilde{y}^{(m)}\\):\\[\\begin{align}\n    \\tilde{\\theta}^{(m)} & \\sim p(\\theta) \\tag{2.8} \\\\\n    \\tilde{y}^{(m)} & \\sim p(y|\\tilde{\\theta}^{(m)})\n    \\tag{2.9}\n\\end{align}\\]set model outputs approximates prior probability distribution. large inconsistencies can spotted distribution measurements, can adjust assumptions regarding prior definition structure observational model. example prior predictive checking shown top right Fig. 2.2, suggests model structures contradict observations.","code":""},{"path":"back-bayes.html","id":"computation","chapter":"2 Bayesian data analysis","heading":"2.3.4 Step 2: computation with Markov Chain Monte Carlo","text":"Except convenient situations, posterior distribution analytically tractable. practice, rather finding exact solution , estimated approximate methods. popular option approximate posterior inference Markov Chain Monte Carlo (MCMC) sampling methods. possible computationally efficient sample directly posterior distribution, Markov Chain simulation used stochastically explore typical set, .e. regions parameter space significant contribution desired expectations. Markov chains used MCMC methods designed stationary distribution posterior distribution. chain long enough, state history chain provides samples typical set \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)\\)\n\\[\\begin{equation}\n    \\theta^{(s)} \\sim p(\\theta | y)\n    \\tag{2.10}\n\\end{equation}\\]\ndraw \\(\\theta^{(s)}\\) contains value parameters model.guide aim explaining MCMC algorithms characteristics, may refer paper (Betancourt (2017)) description state---art Hamiltonian Monte Carlo alogrithm.Posterior expectation values can accurately estimated Monte Carlo estimator. Based exact independent random samples posterior distribution \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right) \\sim p(\\theta | y)\\), expectation function \\(f(\\theta)\\) can estimated \n\\[\\begin{equation}\n    \\mathbb{E}[f(\\theta)] \\approx\n    \\frac{1}{N} \\sum_{n=1}^{N} f(\\theta)^{(n)}\n\\tag{2.11}\n\\end{equation}\\]Markov Chain Monte Carlo estimators converge true expectation values number draws approaches infinity. practice, diagnostics must applied check estimator follows central limit theorem, ensures estimator unbiased finite number draws. purpose first recommended compute (split-)\\(\\hat{R}\\) statistic, Gelman-Rubin statistic, multiple chains initialized different initial positions split two halves (Gelman et al. (2013)). \\(\\hat{R}\\) statistic measures scalar parameter, \\(\\theta\\), ratio samples variance within chain \\(W\\) sample variance combined chains \\(B\\),\\[\\begin{equation}\n    \\hat{R} = \\sqrt{\\frac{1}{W} \\left(\\frac{N-1}{N}W + \\frac{1}{N}B \\right)}\n    \\tag{2.12}\n\\end{equation}\\]\\(N\\) number samples. chains converged, \\(W\\) underestimate variance, since individual chains time range stationary distribution, \\(B\\) overestimate variance, since starting positions chosen overdispersed.Another important convergence diagnostics tool effective sample size (ESS), defined :\\[\\begin{equation}\n    \\text{ESS} = \\frac{N}{1 + 2 \\sum_{l=1}^{\\infty} \\rho_l}\n    \\tag{2.13}\n\\end{equation}\\]\\(\\rho_l\\) lag-\\(l\\) autocorrelation function \\(f\\) history Markov chain. effective sample size estimate number independent samples posterior distribution.diagnostic tools introduced section provide principled workflow reliable Bayesian inferences. readily available Bayesian computation libraries. Based recent improvements \\(\\hat{R}\\) statistic (Vehtari et al. (2021)), recommended use samples \\(\\hat{R} < 1.01\\) \\(\\text{ESS} > 400\\).","code":""},{"path":"back-bayes.html","id":"modelvalidation","chapter":"2 Bayesian data analysis","heading":"2.3.5 Step 3: model checking and validation","text":"model specification learning, third step workflow model checking validation. conducted conclusions drawn, prediction accuracy model estimated.posterior predictive distributionThe basic way checking fit model data draw simulated values trained model compare observed data. non-Bayesian framework, pick likely point estimate parameters, maximum likelihood estimate, use compute model output \\(\\hat{y}\\), conduct residual analysis. Bayesian framework, posterior predictive checking allows possibilities.posterior predictive distribution distribution observable \\(\\tilde{y}\\) (model output) conditioned observed data \\(y\\):\n\\[\\begin{equation}\np\\left(\\tilde{y}|y\\right) = \\int p\\left(\\tilde{y}|\\theta\\right) p\\left(\\theta | y\\right) \\mathrm{d}\\theta\n\\tag{2.14}\n\\end{equation}\\]\ndefinition similar prior predictive distribution given Sec. 2.3.3, except prior \\(p(\\theta)\\) replaced posterior \\(p(\\theta|y)\\). Similarly, simple compute posterior approximated MCMC procedure: first draw finite number parameter vectors \\(\\theta^{(m)}\\) posterior distribution, use compute model output \\(\\tilde{y}^{(m)}\\):\n\\[\\begin{align}\n    \\theta^{(m)} & \\sim p(\\theta|y) \\tag{2.15}\\\\\n    \\tilde{y}^{(m)} & \\sim p(y|\\theta^{(m)})\n    \\tag{2.16}\n\\end{align}\\]\nset model outputs approximates posterior probability distribution.following methods model checking may apply either frequentist Bayesian framework.fitting returns point estimate parameters \\(\\hat{\\theta}\\), single profile model output \\(\\hat{y}\\) can calculated , either compared training data set \\(y_\\mathit{train}\\) separate test data set \\(y_\\mathit{test}\\).fitting returns point estimate parameters \\(\\hat{\\theta}\\), single profile model output \\(\\hat{y}\\) can calculated , either compared training data set \\(y_\\mathit{train}\\) separate test data set \\(y_\\mathit{test}\\).fitting returns posterior distribution \\(p(y|\\theta)\\), comparisons may applied \\(\\tilde{y}^{(m)}\\) samples.fitting returns posterior distribution \\(p(y|\\theta)\\), comparisons may applied \\(\\tilde{y}^{(m)}\\) samples.Measures model adequacyMeasures model adequacyAfter fitting, either ordinary linear regression sophisticated ones, metrics may assess predictive accuracy model.R-squared (\\(R^2\\)) index proportion variance dependent variable explained regression model (closest 1 better)\\[\\begin{equation}\n    R^2 = 1-\\frac{\\sum_{=1}^N\\left(y_i - \\hat{y}_i\\right)^2}{\\sum_{=1}^N\\left(y_i - \\bar{y}_i\\right)^2}\n    \\tag{2.17}\n\\end{equation}\\]root-mean-square-error (RMSE) simply measures differences model predictions \\(\\hat{y}\\) observations \\(y\\) (lower better)\\[\\begin{equation}\n\\mathrm{CV(RMSE)} = \\frac{1}{\\bar{y}} \\sqrt{\\frac{\\sum_{=1}^N\\left(\\hat{y}_i-y_i\\right)^2}{N}}\n\\tag{2.18}\n\\end{equation}\\]Coverage Width-based Criterion (CWC) (Chong, Augenbroe, Yan (2021)), indicator probabilistic forecasts measures quality predictions based accuracy precision.\\(R^2\\) CV-RMSE indices often treated validation metrics. calculated using test data set, can indeed estimate model predictive ability outside training data set. however ensure model correctly captures data generating process: residual analysis .Residual analysis hypothesis unbiased model assumes difference model output observed temperature sequence independent, identically distributed variables following Gaussian distribution zero mean constant covariance. example linear regression model, condition may read:\n\\[\\begin{equation}\n    r_i = y_i - \\left( \\hat{\\theta}_0 + \\hat{\\theta}_1 X_{,1} + \\hat{\\theta}_2 X_{,2} \\right) \\sim N(0,\\sigma)\n    \\tag{2.19}\n\\end{equation}\\]\n\\(r_i\\) prediction residuals. Residual analysis process checking validity four hypotheses (independence, identical distribution, zero mean, constant variance), main step model validation. allows identifying problems may arise fitting regression model (James et al. (2013)), among : correlation error terms, outliers, high leverage points, colinearity…\nFigure 2.3: Example residual plots ordinary linear regression R: fitted vs residuals, Q-Q plot, scale location residuals vs leverage\nResidual analysis can performed array tests graphs, shown Fig. 2.3.simple plot residuals versus model output display trend. goes plot residuals vs explanatory variables. trend visible, model structure probably insufficient explain data.quantile-quantile (Q-Q) plot (upper right) way check distribution residuals approximately GaussianThe scale-location plot (lower left) way check hypothesis homoskedasticity, .e. constant varianceThe residuals vs leverage plot (lower right) allows identifying eventual outliers high leverage points.\nFigure 2.4: Autocorrelation function (top) cumulated periodogram (bottom) insufficient model (left) sufficient model (right)\nimportantly, correlation among error terms checked. autocorrelation function (ACF) checks independence residuals may reveal lag dependencies suggest influences model properly take account. particularly important time series models, therefore well explained time series litterature (Shumway Stoffer (2000)). Alternatively, Durbin-Watson test quantitatively checks autocorrelation regression models. “correlation among error terms, estimated standard errors tend underestimate true standard errors. result, confidence prediction intervals narrower .”(James et al. (2013))residuals display unequal variances correlations, inferences predictions fitted model used. model modified re-trained according practitioner’s expertise diagnostics analysis: additional explanatory variables can included possible.","code":""},{"path":"back-bayes.html","id":"bayesian-mv-in-practice","chapter":"2 Bayesian data analysis","heading":"2.4 Bayesian M&V in practice","text":"","code":""},{"path":"back-bayes.html","id":"estimating-savings-and-their-uncertainty","chapter":"2 Bayesian data analysis","heading":"2.4.1 Estimating savings and their uncertainty","text":"following workflows M&V can followed regardless chosen type model (regression model options , B C, GP emulator option D). choice workflow mostly depend availability data baseline reporting periods.\nFigure 2.5: Estimation savings uncertainty avoided consumption workflow. step model validation displayed.\nsummary workflow estimate savings uncertainty, following reporting period basis, avoided energy consumption. assume measurement boundaries defined data \\(y_\\mathit{base}\\) \\(y_\\mathit{repo}\\) recorded baseline reporting period respectively.standard approaches, choose model structure describe data , formulate likelihood function. Formulate eventual “expert knowledge” assumptions form prior probability distributions.Run MCMC () algorithm obtain set samples \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)\\) approximates posterior distribution parameters conditioned baseline data \\(p\\left(\\theta | y_\\mathit{base}\\right)\\). Validate inference checking convergence diagnostics: R-hat, ESS, etc.Validate model computing predictions baseline period \\(p\\left(\\tilde{y}_\\mathit{base} | y_\\mathit{base}\\right)\\). can done taking (representative set ) samples \\(\\theta^{(s)}\\) individually, running model simulation \\(\\tilde{y}_\\mathit{base}^{(s)} \\sim p\\left(y_\\mathit{base} | \\theta=\\theta^{(s)}\\right)\\) . set simulations generates posterior predictive distribution baseline period, statistic can derived (mean, median, prediction intervals quantile, etc.). measures model validation (R-squared, net determination bias, t-statistic…) can computed either mean, samples order obtain probability densities.Compute reporting period predictions discrete way: sample \\(\\theta^{(s)}\\) generates profile \\(\\tilde{y}_\\mathit{repo}^{(s)} \\sim p\\left(y_\\mathit{repo} | \\theta=\\theta^{(s)}\\right)\\), set simulations generates posterior predictive distribution reporting period.Since reporting period prediction \\(\\tilde{y}_\\mathit{repo}^{(s)}\\) can compared measured reporting period consumption \\(y_\\mathit{repo}\\), can obtain S values energy savings, distribution approximate posterior probability savings.\\[\\begin{align}\n\\Delta e^{(s)} & = \\sum_{=1}^n\\left(\\tilde{y}_\\mathit{repo}^{(s)}()-y_\\mathit{repo}()\\right) \\tag{2.19} \\\\\n& \\sim p\\left(\\Delta e | y_\\mathit{base}, y_\\mathit{repo}\\right) \\tag{2.20}\n\\end{align}\\]normalised savings workflow, numerical model trained baseline reporting period data. trained model predicts energy consumption period normalised conditions, savings estimated comparing predictions.Two posterior distributions produced \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)_\\mathit{base}\\) \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)_\\mathit{repo}\\), similar way model trained period. validation metrics model checked using posterior predictions training period.Two posterior distributions produced \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)_\\mathit{base}\\) \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)_\\mathit{repo}\\), similar way model trained period. validation metrics model checked using posterior predictions training period.model computes set \\(S\\) posterior predictions normalised period, sampling parameter posterior distribution:\n\\[\\begin{align}\n\\tilde{y}_{\\mathit{norm}|\\mathit{base}}^{(s)} \\sim p\\left(y_\\mathit{norm} | \\theta=\\theta_\\mathit{base}^{(s)}\\right) \\tag{2.21}\\\\\n\\tilde{y}_{\\mathit{norm}|\\mathit{repo}}^{(s)} \\sim p\\left(y_\\mathit{norm} | \\theta=\\theta_\\mathit{repo}^{(s)}\\right)\\tag{2.22}\n\\end{align}\\]model computes set \\(S\\) posterior predictions normalised period, sampling parameter posterior distribution:\n\\[\\begin{align}\n\\tilde{y}_{\\mathit{norm}|\\mathit{base}}^{(s)} \\sim p\\left(y_\\mathit{norm} | \\theta=\\theta_\\mathit{base}^{(s)}\\right) \\tag{2.21}\\\\\n\\tilde{y}_{\\mathit{norm}|\\mathit{repo}}^{(s)} \\sim p\\left(y_\\mathit{norm} | \\theta=\\theta_\\mathit{repo}^{(s)}\\right)\\tag{2.22}\n\\end{align}\\]can obtain \\(S\\) values savings \\(S\\) pairs predictions:\n\\[\\begin{equation}\n\\Delta e^{(s)} = \\sum_{=1}^n\\left(\\tilde{y}_{\\mathit{norm}|\\mathit{base}}^{(s)}() - \\tilde{y}_{\\mathit{norm}|\\mathit{repo}}^{(s)}()\\right) \\tag{2.23}\n\\end{equation}\\]can obtain \\(S\\) values savings \\(S\\) pairs predictions:\n\\[\\begin{equation}\n\\Delta e^{(s)} = \\sum_{=1}^n\\left(\\tilde{y}_{\\mathit{norm}|\\mathit{base}}^{(s)}() - \\tilde{y}_{\\mathit{norm}|\\mathit{repo}}^{(s)}()\\right) \\tag{2.23}\n\\end{equation}\\]","code":""},{"path":"back-bayes.html","id":"tools","chapter":"2 Bayesian data analysis","heading":"2.4.2 Software tools","text":"rest guide series tutorials reader may see methods practice. Unlike classical regression, modelling part requires stepping Excel spreadsheets using dedicated computing environment.use Stan platform statistical modelling. algorithms accessible interfaces scientific computing languages: Python, R, Julia, Matlab…majority Stan users seem favor R language, hence choice tutorials. alternative full Stan models, rstanarm R package “people open Bayesian inference using Bayesian software easier use frequentist software otherwise”Python users, PyMC Pyro popular Bayesian modelling alternatives. Julia users may use Turing. Stan models propose can still interfaced two languages.Additionally, specialised plotting libraries made exploratory analysis Bayesian models. recommend users give try:bayesplot R package Stan models;ArviZ package Python Julia.","code":""},{"path":"optClinreg.html","id":"optClinreg","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3 Tutorial 1: linear regression and introduction to Stan","text":"first tutorial serves introduction Stan platform, shows Bayesian analysis obtains uncertainty assessments classical methods, analytical solutions available.purpose, use short dataset ordinary linear regression model.","code":""},{"path":"optClinreg.html","id":"data","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.1 Data","text":"data monthly measurements whole-facility energy use (kWh), well heating degree-days cooling degree-days (°C.day).","code":"\nlibrary(rstan)\nlibrary(tidyverse)\n\n# Baseline data: cooling and heating degree days, energy use\ndf.pre <- data.frame(cdd = c(0, 10, 15, 21, 21, 14, 0, 0, 0, 0, 0, 0),\n                     hdd = c(14, 0, 0, 0, 0, 0, 2, 20, 18, 32, 27, 20),\n                     use = c(35936, 22260, 20970, 25438, 28547, 24394,\n                             24224, 38767, 42205, 49649, 43540, 43734))\n# Reporting period data: cooling and heating degree days, energy use\ndf.post <- data.frame(cdd = c(0, 3, 13, 23, 19, 16, 0, 0, 0, 0, 0, 0),\n                      hdd = c(5, 0, 0, 0, 0, 0, 2, 19, 20, 24, 25, 14),\n                      use = c(25416, 17445, 13626, 19295, 17970, 15158,\n                              13293, 35297, 35665, 38562, 33383, 37244))\n\nggplot(df.pre, aes(x=hdd, y=use)) + geom_point()"},{"path":"optClinreg.html","id":"model-specification-first-look-at-a-stan-model","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.2 Model specification: first look at a Stan model","text":"","code":""},{"path":"optClinreg.html","id":"ordinary-linear-regression","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.2.1 Ordinary linear regression","text":"quick look data, can assume linear relationship dependent variable (energy use) explanatory variables (hdd cdd).wrote longer lecture ordinary linear regression . don’t differentiate simple multiple regression, .e. models one several explanatory variable, since solved way.consider dependent variable \\(y\\), set \\(k\\) explanatory (independent) variables \\(x=(x_1,...,x_k)\\), assume series \\(n\\) values measured. therefore vector \\(\\mathbf{y}=\\left\\{y_i\\right\\}_{=1}^n\\) matrix \\(X = \\left\\{x_{i1},...x_{ik}\\right\\}_{=1}^n\\) dependent independent variable measurements.ordinary linear regression model states distribution \\(y_i\\) given predictors \\(\\mathbf{X}_i\\) normal mean linear function:\n\\[\\begin{align}\n    y_i & = \\alpha + \\beta_1 x_{i1} + ... + \\beta_k x_{ik} + \\varepsilon_i  \\tag{3.1} \\\\\n  \\varepsilon_i & \\sim \\mathrm{normal}(0, \\sigma) \\tag{3.2}\n\\end{align}\\]\nmatrix form:\n\\[\\begin{equation}\n    \\mathbf{y} = \\alpha + \\mathbf{X} \\cdot \\mathbf{\\beta} + \\mathbf{\\varepsilon}    \\tag{3.3}\n\\end{equation}\\]\nparameters \\((\\alpha, \\beta_1, ..., \\beta_k, \\sigma)\\) vector coefficients determined. Ordinary linear regression assumes normal linear model observation errors \\(\\varepsilon_i\\) independent equal variance \\(\\sigma^2\\) (hypothesis homoscedasticity).","code":""},{"path":"optClinreg.html","id":"linear-regression-with-stan","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.2.2 Linear regression with Stan","text":"Linear regression naturally first example given Stan documentation. following model extended bit purpose study.Stan model can either written separate file, included R script (language) follows:code made several blocks delimited braces. seven types blocks Stan model, used four . order important code, describe another order:model block center Stan code. declare model relates dependent variable \\(y\\) (energy use) explanatory variables \\(x\\) (heating cooling degree-days):line states expect \\(y\\) normally distributed around linear function \\(\\alpha + \\mathbf{X} \\cdot \\mathbf{\\beta}\\), standard deviation \\(\\sigma\\). identical Eq. (3.3).data block contains definition data passed model. variables declared block arguments model use: vector \\(\\mathbf{y}\\) matrix \\(\\mathbf{X}\\) “pre” “post” periods. number data items also requirement, since used variable Stan model.parameters block declares variables learned model training: intercept \\(\\alpha\\), slopes \\(\\beta\\) noise scale \\(\\sigma\\).generated quantities block optional influence model training. used evaluate function parameters \\(f(\\theta)\\) every sample, may directly obtain posterior distribution \\(p(f(\\theta)|y)\\) (see Eq. (2.11)). Two variables computed :\nprediction model’s prediction energy use post-ECM period. uses parameter models \\((\\alpha, \\beta, \\sigma)\\) learned pre-retrofit data, post-retrofit matrix dependent variables \\(\\mathbf{X}\\).\nsavings total difference measured predicted post-retrofit energy use.\nincluding two variables generated quantities block.\nprediction model’s prediction energy use post-ECM period. uses parameter models \\((\\alpha, \\beta, \\sigma)\\) learned pre-retrofit data, post-retrofit matrix dependent variables \\(\\mathbf{X}\\).savings total difference measured predicted post-retrofit energy use.\nincluding two variables generated quantities block.","code":"\nlinearregression <- \"\ndata {\n// Baseline data (pre)\n  int<lower=0> N;     // number of data items\n  int<lower=0> K;     // number of predictors\n  matrix[N, K] x;     // predictor matrix\n  vector[N] y;        // outcome vector\n// Reporting period data (post)\n  int<lower=0> N_post;  // number of data items\n  matrix[N, K] x_post;     // predictor matrix\n  vector[N] y_post;        // outcome vector\n}\nparameters {\n  real alpha;           // intercept\n  vector[K] beta;       // coefficients for predictors\n  real<lower=0> sigma;  // error scale\n }\nmodel {\n  y ~ normal(alpha + x * beta, sigma);  // likelihood\n}\ngenerated quantities {\n  vector[N_post] prediction;\n  real savings = 0;\n  for (n in 1:N_post) {\n    prediction[n] = normal_rng(x_post[n] * beta + alpha, sigma);\n    savings += prediction[n] - y_post[n];\n  }\n}\n\"model {\n  y ~ normal(alpha + x * beta, sigma);\n}"},{"path":"optClinreg.html","id":"model-fit-and-inference-diagnostics","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.3 Model fit and inference diagnostics","text":"","code":""},{"path":"optClinreg.html","id":"sampling-from-the-posterior","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.3.1 Sampling from the posterior","text":"next step map data contained df.pre df.post dataframes Stan model. defining list variables match items defined data block:first column \\(\\mathbf{X}\\) matrix cooling degree-days, second column heating degree-days.can now get fit following command. important arguments :model_code points Stan code. chose write R code separate file, instance called linearregression.stan, may replace line model_code = linearregression file = 'linearregression.stan' (pointing appropriate location file).data points list variables just defines.chains least 4.iter number iterations per chain.warmup number discarded iterations start every chain.\nDefault values chains = 4, warmup = 1000 iter = 2000, result chains*(iter-warmup)=4000 samples. appeared slightly insufficient case small dataset, raised iter.Model fitting takes longer first time stan() command run, model must first compiled. compilation however required per model, means running new data faster.","code":"\ndata_list <- list(N = nrow(df.pre),\n                  K = 2,\n                  x = df.pre %>% select(cdd, hdd),\n                  y = df.pre$use,\n                  N_post = nrow(df.post),\n                  x_post = df.post %>% select(cdd, hdd),\n                  y_post = df.post$use)\nfit <- stan(\n  model_code = linearregression,  # Stan program\n  data = data_list,        # named list of data\n  chains = 4,               # number of Markov chains\n  warmup = 1000,            # number of warmup iterations per chain\n  iter = 3000,              # total number of iterations per chain\n  cores = 2,                # number of cores (could use one per chain)\n  refresh = 0,              # progress not shown\n)"},{"path":"optClinreg.html","id":"results","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.3.2 Results","text":"fit object returned stan associated methods print, plot pairs, letting us first look results.\n* print method shows posterior metrics parameters generated quantities: mean, standard deviation, quantiles, effective sample size, R-hat.traceplot shows traces selected parameters variables. fitting converged, traces coincide approximate posterior distributions.pairs shows pairwise relationships parameters. Strong interactions parameters indication model re-parameterised.","code":"\nprint(fit, pars=c(\"alpha\", \"beta\", \"sigma\", \"savings\"), probs=c(.025,.5,.975))## Inference for Stan model: 08fcb401f6af5c61fc0cf0e3fcc190e3.\n## 4 chains, each with iter=3000; warmup=1000; thin=1; \n## post-warmup draws per chain=2000, total post-warmup draws=8000.\n## \n##             mean se_mean       sd     2.5%      50%     97.5% n_eff Rhat\n## alpha   22865.24   55.41  2530.45 17887.63 22842.59  27940.48  2086    1\n## beta[1]   114.42    3.59   170.05  -234.15   115.38    448.06  2245    1\n## beta[2]   872.00    2.70   124.09   620.86   872.88   1123.90  2116    1\n## sigma    3126.08   19.66   923.05  1928.18  2946.97   5376.23  2204    1\n## savings 75719.34  202.56 16209.73 43451.18 75701.18 107866.26  6404    1\n## \n## Samples were drawn using NUTS(diag_e) at Fri Mar 24 13:35:02 2023.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\ntraceplot(fit, pars=c(\"alpha\", \"beta\", \"sigma\", \"savings\"))\npairs(fit, pars=c(\"alpha\", \"beta\", \"sigma\", \"savings\"))"},{"path":"optClinreg.html","id":"inference-diagnostics","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.3.3 Inference diagnostics","text":"Running stan() command may return variety warnings help users diagnose resolve underlying modelling problems.order draw reliable inferences results, need least green lights:High enough effective sample size (ESS) parameters (seen table shown print);R-hat lower 1.01, ensure chains converged;remaining warnings BFMI (Bayesian fraction missing information), divergent transitions maximum treedepth.criteria may seem obscure new users Bayesian computation, ignored. guide suggests ways solve problems. part larger workflow model building, testing critique/evaluation.first thing try traces converged increase warmup iterations. may enough get better ESS R-hatThere possible “hidden” adjustments MCMC algorithm solve warnings (see example)problems remain, might sign model inadequacy. solution reduce model use stronger priors, data may sufficient inform parameters.Diagnostics may facilitated use specialised plotting libraries made exploratory analysis Bayesian models:bayesplot R packageThe ArviZ package Python Julia methods dedicated inference diagnostics","code":"fit <- stan(...\n            control = list(adapt_delta = 0.99, stepsize = 0.01, max_treedepth = 15)\n)"},{"path":"optClinreg.html","id":"model-checking-and-validation","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.4 Model checking and validation","text":"","code":""},{"path":"optClinreg.html","id":"measures-of-model-adequacy","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.4.1 Measures of model adequacy","text":"MCMC convergence necessary, guarantee model best choice case! Assessing adequacy fitted model just necessary Bayesian framework classical frequentist methods.extract function returns model parameters generated quantities named list.instance la$alpha la$savings hold value parameter \\(\\alpha\\) estimated savings many samples (example , \\(N_s=8000\\) samples). Similarly, la$prediction \\(N_s\\times 12\\) matrix \\(N_s\\) samples predicted energy use.way summarise posterior predictions quantiles:can calculate usual metrics mean posterior prediction: coefficient determination \\(R^2\\), CV(RMSE), F-statistic…Prediction residuals low autocorrelation. can checked Durbin-Watson statistic, autocorrelation plot:simple linear model low autocorrelation residuals, \\(R^2\\) index quite low: significant part data’s variance unexplained.","code":"\nla <- rstan::extract(fit, permuted = TRUE)\nsummary(la$savings)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  -44706   65591   75701   75719   85880  159172\n# median, lower and upper bounds of the 95% prediction intervals\npredict <- apply(la$prediction, 2, quantile, probs=c(0.025, 0.5, 0.975))\n# mean prediction\npredict.mean <- colMeans(la$prediction)\n\n# Plot of the median and 95% prediction intervals\nggplot(mapping = aes(x = array(1:nrow(df.pre)))) +\n  geom_point(mapping = aes(y = df.pre$use)) +\n  geom_line(mapping = aes(y = predict[2,]), color='red') +\n  geom_ribbon(mapping = aes(ymin=predict[1,], ymax=predict[3,]), fill='red', alpha=0.1) +\n  labs(x = \"Month\", y=\"Energy use (kWh)\")\nresiduals <- predict.mean - df.pre$use        # residuals\nssres <- sum(residuals^2)                     # sum of squared residuals\nsstot <- sum((df.pre$use-mean(df.pre$use))^2) # total sum of squares\n\nR2 <- 1 - ssres / sstot   # coefficient of determination\nCVRMSE <- sqrt(ssres / nrow(df.pre)) / mean(df.pre$use)\n\nprint(paste(\"R2 =\", R2))\nprint(paste(\"CV(RMSE) =\", CVRMSE))## [1] \"R2 = 0.807417272332704\"\n## [1] \"CV(RMSE) = 0.127133738673795\"\nacf(residuals)"},{"path":"optClinreg.html","id":"checking-model-parameters","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.4.2 Checking model parameters","text":"Individual parameter adequacy can checked \\(t\\)-statistic \\(p\\)-value.can see one \\(p\\)-value 0.05: beta[1] regression coefficient cooling degree-days.pairwise correlation parameters already visible pairplot shown earlier. high correlation , can confirm quantitatively:","code":"\n# Trace of all parameters and generated quantities\ntraces <- as.data.frame(fit)\n# Only the parameters\ntraces.p <- traces %>% select('alpha', 'beta[1]', 'beta[2]', 'sigma')\n\n# The t-statistic is the ratio of mean to standard deviation of parameters\nt_stat <- colMeans(traces.p) / sapply(traces.p, sd)\n# The p-value is easy to calculate from the t statistics\nptest <- 2*pt(-abs(t_stat), df=nrow(df.pre))\n\nprint(ptest)##        alpha      beta[1]      beta[2]        sigma \n## 1.058439e-06 5.137977e-01 1.381006e-05 5.401048e-03\ncor(traces.p)##               alpha     beta[1]     beta[2]       sigma\n## alpha    1.00000000 -0.85153006 -0.88297395  0.01072059\n## beta[1] -0.85153006  1.00000000  0.74474306 -0.03438873\n## beta[2] -0.88297395  0.74474306  1.00000000 -0.01472333\n## sigma    0.01072059 -0.03438873 -0.01472333  1.00000000"},{"path":"optClinreg.html","id":"prediction-of-savings","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.5 Prediction of savings","text":"partially reassured adequacy model: \\(R^2\\) high, one parameter may statistically significant, parameters quite correlated. autocorrelation criterion however satisfactory: means may obtain unbiased estimates energy savings, probably high uncertainty.Let’s fit regular deterministic linear model, order compare results Bayesian method:Yes, simple.coefficients Bayesian output. Without model checking, can expect conclusions.Let’s now compare energy use predictions post-retrofit period, Bayesian method (red) classical method (blue):Predictions methods look almost exactly . Finally, let’s compare basis energy savings predictions. following block generates table containing mean, lower upper bounds 95% confidence interval, predicted energy savings.","code":"\nfit2 <- lm(use ~ cdd + hdd, df.pre)\nsummary(fit2)## \n## Call:\n## lm(formula = use ~ cdd + hdd, data = df.pre)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3608.1 -1596.3  -225.6  1464.2  3636.7 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  22860.4     2136.0  10.702 2.03e-06 ***\n## cdd            114.5      142.6   0.803    0.443    \n## hdd            872.7      104.2   8.374 1.53e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2681 on 9 degrees of freedom\n## Multiple R-squared:  0.9421, Adjusted R-squared:  0.9292 \n## F-statistic: 73.24 on 2 and 9 DF,  p-value: 2.702e-06\npredict.2 <- predict(fit2, newdata = df.post, interval = \"prediction\", level=0.95)\n\nxplot <- array(1:nrow(df.post))\nggplot(mapping = aes(x = xplot)) +\n  geom_point(mapping = aes(y = df.post$use)) +\n  geom_line(mapping = aes(y = predict[2,]), color='red') +\n  geom_line(mapping = aes(y = predict.2[,1]), color='blue') +\n  geom_ribbon(mapping = aes(ymin=predict[1,], ymax=predict[3,]), fill='red', alpha=0.1) +\n  geom_ribbon(mapping = aes(ymin=predict.2[,2], ymax=predict.2[,3]), fill='blue', alpha=0.1)\nmethod <- c(\"bayesian\", \"classical\")\n# Mean savings\nmean.savings <- c(mean(la$savings),\n                  sum(predict.2[,1] - df.post$use))\n# Lower and upper bounds of the 95% confidence interval of savings\nlower.bound <- c(sum(predict[1,] - df.post$use),\n                 sum(predict.2[,2] - df.post$use))\nupper.bound <- c(sum(predict[3,] - df.post$use),\n                 sum(predict.2[,3] - df.post$use)) \nsvgs <- data.frame(method, mean.savings, lower.bound, upper.bound)\n\nprint(svgs)##      method mean.savings lower.bound upper.bound\n## 1  bayesian     75719.34  -11229.684    162575.0\n## 2 classical     75564.54   -6385.537    157514.6"},{"path":"optClinreg.html","id":"conclusion","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.6 Conclusion","text":"tutorial, showed perform Bayesian linear regression Stan, typical M&V workflow. estimate post-retrofit energy savings, adjusted heating cooling degree-days.showed obtain results (parameter estimates, model validation metrics, energy use predictions, savings uncertainty) Bayesian approach deterministic ordinary linear regression method. Bayesian method seems much complicated classical method, ’ll show next tutorials workflow remain regardless model complexity, classical approach may longer simple solutions estimating savings uncertainty.","code":""},{"path":"optCchangepoint.html","id":"optCchangepoint","chapter":"4 Tutorial 2: change-point model","heading":"4 Tutorial 2: change-point model","text":"click interactive version tutorialThis based option C example already wrote. need simplify parts , elaborate parts.data used example hourly energy consumption outdoor air temperature data 11 commercial buildings (office/retail), publicly available :https://openei.org/datasets/dataset/consumption-outdoor-air-temperature-11-commercial-buildingsWe using two data files, respectively labeled Building 6 (Office “Pre”), Building 6 (Office “Post”).","code":"\nlibrary(rstan)\nlibrary(tidyverse)\nlibrary(lubridate)"},{"path":"optCchangepoint.html","id":"the-data","chapter":"4 Tutorial 2: change-point model","heading":"4.1 The data","text":"","code":""},{"path":"optCchangepoint.html","id":"loading-and-displaying","chapter":"4 Tutorial 2: change-point model","heading":"4.1.1 Loading and displaying","text":"following block loads two separate data files:building60preoffice.csv baseline period file, saved df.base variablebuilding60postoffice.csv reporting period file, saved df.repo variableThe Date column files converted DateTime type new column. , baseline dataset displayed first exploratory look data.data hourly time step size. Every hour, outdoor air temperature (OAT °F) energy use (kW) available.energy use higher summer winter -. suggests consumption data includes heating cooling appliances.Week-ends clearly visible lower consumption working days week.","code":"\n# Baseline data: one year\ndf.base <- read_csv(\"data/Long-term 11 commercial buildings/building60preoffice.csv\") %>% \n  mutate(DateTime = mdy_hm(Date),\n         Date = as_date(DateTime))\n\n# Post-retrofit data: one year\ndf.repo <- read_csv(\"data/Long-term 11 commercial buildings/building61duringoffice.csv\") %>% \n  mutate(DateTime = mdy_hm(Date),\n         Date = as_date(DateTime))\n\n# Plot the original data\nhead(df.base)## # A tibble: 6 x 4\n##   Date         OAT `Building 6 kW` DateTime           \n##   <date>     <dbl>           <dbl> <dttm>             \n## 1 2009-01-02  41.6            23.3 2009-01-02 00:00:00\n## 2 2009-01-02  40.9            23.1 2009-01-02 01:00:00\n## 3 2009-01-02  39.5            23.7 2009-01-02 02:00:00\n## 4 2009-01-02  36.3            29.1 2009-01-02 03:00:00\n## 5 2009-01-02  32.8            35.6 2009-01-02 04:00:00\n## 6 2009-01-02  32.5            45.5 2009-01-02 05:00:00\nggplot(data = df.base) + geom_line(mapping = aes(x=DateTime, y=`Building 6 kW`))"},{"path":"optCchangepoint.html","id":"subset-selection","chapter":"4 Tutorial 2: change-point model","heading":"4.1.2 Subset selection","text":"Averaging data daily time steps allow overlook dependence consecutive measurements. turn, allows using model much simpler time series models, capable low frequency predictions.following block creates new datasets original ones:Measurements daily averagedTemperatures switched °C international suitability.categorical variable added indicate week ends., plot daily energy use \\(E\\) (kWh) versus outdoor temperature \\(T\\) (°C) values week.end categorical variable.seems fitting train separate models working days week ends, energy use clearly different two sets. tutorial, consider working days, aren’t many available data points week ends, possible .","code":"\ndaily.average <- function(df) {\n  df %>% \n    group_by(Date) %>% \n    summarise(OAT = mean(OAT),\n              E = sum(`Building 6 kW`),\n              .groups = 'drop'\n    ) %>% \n    mutate(wday = wday(Date),\n           week.end = wday==1 | wday==7,\n           T = (OAT-32) * 5/9)\n}\n\ndf.base.daily <- daily.average(df.base)\ndf.repo.daily <- daily.average(df.repo)\n\nggplot(data = df.base.daily) +\n  geom_point(mapping = aes(x=T, y=E, color=week.end))\ndf.base.daily <- daily.average(df.base) %>% filter(!week.end)\ndf.repo.daily <- daily.average(df.repo) %>% filter(!week.end)"},{"path":"optCchangepoint.html","id":"modelling-and-training","chapter":"4 Tutorial 2: change-point model","heading":"4.2 Modelling and training","text":"","code":""},{"path":"optCchangepoint.html","id":"model-definition","chapter":"4 Tutorial 2: change-point model","heading":"4.2.1 Model definition","text":"looking data, can suggest using change-point model include effects heating cooling, separate week ends working days. expected daily energy use \\(E\\) (kWh per day) function outdoor temperature \\(T\\) number parameters:\\[p(E|T) \\sim \\mathcal{N}\\left[\\alpha + \\beta_{h}(\\tau_{h}-T)^+ + \\beta_{c}(T-\\tau_{c})^+, \\sigma\\right]\\]\\(h\\) \\(c\\) subscripts indicate heating cooling modes. \\(+\\) superscript indicates term applied zero.equation mean expect energy use \\(E\\) normal distribution centered around change-point model, constant standard deviation \\(\\sigma\\). particularities Bayesian statistics : normal distribution can replaced probability distribution; error term \\(\\sigma\\) can formulated function inputs; etc.model 6 possible parameters, ordinary linear regression. following method also exactly decided complexify model, instance assuming non-linear profiles side change points, categorical variables.","code":""},{"path":"optCchangepoint.html","id":"model-specification-with-stan","chapter":"4 Tutorial 2: change-point model","heading":"4.2.2 Model specification with Stan","text":"example, use Stan probabilistic programming language, allows full Bayesian statistical inference.https://mc-stan.org/STAN model block text can either written separate file, script current code. Specifying model STAN takes certain learning curve, unlocks full flexibility Bayesian analysis., list called model_data created, maps part data appropriate variable STAN model.","code":"\nchangepoint <- [1679 chars quoted with '\"']\nmodel_data <- list(\n  N_base = nrow(df.base.daily),\n  t_base = df.base.daily$T,\n  y_base = df.base.daily$E,\n  N_repo = nrow(df.repo.daily),\n  t_repo = df.repo.daily$T,\n  y_repo = df.repo.daily$E\n)"},{"path":"optCchangepoint.html","id":"step-2-model-fitting","chapter":"4 Tutorial 2: change-point model","heading":"4.2.3 Step 2: Model fitting","text":"Now model specified data mapped variables, syntax model fitting .One disadvantage Bayesian inference MCMC algorithm takes much longer converge typical least-squares model fitting method. Running code might take minute using 365 data points, Bayesian approach might become problematic larger data files (100,000 rows ).Fitting may result number warnings, telling us problems may occurred: divergent transitions, large R-hat values, low Effective Sample Size… Obtaining fit without warnings takes practice essential unbiased interpretation inferred variables predictions. guide Stan’s warnings address available : https://mc-stan.org/misc/warnings.htmlThe first step solving warnings re-run algorithm different controls: iter, max_treedepth, etc. problems persist, possible model complex information data able provide simplified, stronger priors proposed. lot problems can solved prior information. specific case, especially useful variables equation week-ends, since lot data points.","code":"\n# Fitting the model\nfit1 <- stan(\n  model_code = changepoint,  # Stan program\n  data = model_data,        # named list of data\n  chains = 4,               # number of Markov chains\n  warmup = 1000,            # number of warmup iterations per chain\n  iter = 2000,              # total number of iterations per chain\n  cores = 2,                # number of cores (could use one per chain)\n  refresh = 0,              # progress not shown\n)"},{"path":"optCchangepoint.html","id":"validation-and-results","chapter":"4 Tutorial 2: change-point model","heading":"4.3 Validation and results","text":"Stan returns object (called fit1 ) distributions outputs parameters fitted model can accessedhttps://cran.r-project.org/web/packages/rstan/vignettes/stanfit-objects.htmlThe MCMC algorithm produces chain samples \\(\\theta^{(m)}\\) parameters, approximate posterior distributions. case, parameter model represented chain 6,000 draws: draws, can extract statistics need: mean, median, quantiles, \\(t\\)-score \\(p\\)-values, etc.","code":""},{"path":"optCchangepoint.html","id":"parameters","chapter":"4 Tutorial 2: change-point model","heading":"4.3.1 Parameters","text":"first validation step, useful take look values parameters estimated algorithm. , use three diagnostics tools:print method shows table parameters, much like display ordinary linear regressiontraceplot shows traces selected parameters. fitting converged, traces approximate posterior distributionspairs shows pairwise relationships parameters. Strong interactions parameters indication model re-parameterised.","code":"\nprint(fit1, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"savings\"))## Inference for Stan model: 3824f231226c57790491f93819ce4cf5.\n## 4 chains, each with iter=2000; warmup=1000; thin=1; \n## post-warmup draws per chain=1000, total post-warmup draws=4000.\n## \n##             mean se_mean      sd     2.5%      25%      50%      75%    97.5%\n## alpha     829.49    0.21   12.18   803.68   821.85   830.14   837.55   852.14\n## beta_h     33.37    0.06    2.66    28.17    31.62    33.36    35.11    38.54\n## tau_h       6.52    0.02    0.77     5.27     5.97     6.45     6.96     8.33\n## beta_c     29.16    0.06    3.11    23.17    27.00    29.14    31.26    35.40\n## tau_c      15.75    0.02    0.99    13.59    15.13    15.83    16.48    17.40\n## sigma      96.68    0.09    4.22    88.79    93.76    96.60    99.48   105.03\n## savings 46477.31   36.47 2302.20 41973.79 44939.28 46488.47 48056.04 51031.48\n##         n_eff Rhat\n## alpha    3230    1\n## beta_h   2222    1\n## tau_h    2119    1\n## beta_c   2323    1\n## tau_c    2314    1\n## sigma    2130    1\n## savings  3984    1\n## \n## Samples were drawn using NUTS(diag_e) at Fri Mar 24 11:10:06 2023.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\ntraceplot(fit1, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"lp__\"))\npairs(fit1, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"savings\"))"},{"path":"optCchangepoint.html","id":"predictions","chapter":"4 Tutorial 2: change-point model","heading":"4.3.2 Predictions","text":"https://mc-stan.org/docs/2_26/stan-users-guide/posterior-prediction-chapter.htmlOur main goal compare energy use measured reporting period \\(y_\\mathit{repo}\\) predictions fitted model. Since probabilistic model, outcome actually probability distribution \\(p\\left(y_\\mathit{repo}|x_\\mathit{repo}, x_\\mathit{base}, y_\\mathit{base}\\right)\\), based observed values model inputs \\(x\\) baseline reporting periods, observed energy use baseline period \\(y_\\mathit{base}\\).-called posterior predictive distribution \\(p\\left(y_\\mathit{repo}|...\\right)\\) already directly available, value \\(y_\\mathit{repo}\\) (time step) directly calculated Stan model value \\(\\theta^{(m)}\\).\\[ p\\left(y_\\mathit{repo}|...\\right) \\approx \\frac{1}{M} \\sum_{m=1}^M p\\left(y_\\mathit{repo}|x_\\mathit{repo},\\theta^{(m)}\\right) \\]\nFirst, let us look posterior predictive distribution baseline period, order validate model compared training data:","code":"\n# Extracting full predictive distributions from the stanfit object\nla <- rstan::extract(fit1, permuted = TRUE)\ny_base_pred <- la$y_base_pred\n\n# Quantiles\ny_base_quan <- apply(y_base_pred, 2, quantile, probs=c(0.025, 0.5, 0.975))\n\n# Adding prediction quantiles to the baseline dataframe\ndf.base.daily <- df.base.daily %>% mutate(pred_low = y_base_quan[1, ],\n                                          pred_med = y_base_quan[2, ],\n                                          pred_up = y_base_quan[3, ])\n\n# Plot\nggplot(data = df.base.daily) +\n  geom_point(mapping = aes(x=T, y=E)) +\n  geom_line(mapping = aes(x=T, y=pred_med), color='red') +\n  geom_ribbon(mapping = aes(x=T, ymin=pred_low, ymax=pred_up), fill='red', alpha=0.1)"},{"path":"optCchangepoint.html","id":"residuals","chapter":"4 Tutorial 2: change-point model","heading":"4.3.3 Residuals","text":"important validation step check autocorrelation residuals fitted model, baseline data used fitting. Autocorrelation often sign insufficient model complexity, form model error term appropriately chosen.two graphs show:Residuals vs Date, order display eventual autocorrelationresiduals vs Temperature","code":"\nggplot(data = df.base.daily) +\n  geom_line(mapping = aes(x=Date, y=pred_med-E)) +\n  geom_ribbon(mapping = aes(x=Date, ymin=pred_low-E, ymax=pred_up-E), alpha=0.2)\nresiduals <- colMeans(la$y_base_pred) - df.base.daily$E\n\nggplot() +\n  geom_point(mapping = aes(x=residuals, y=lag(residuals, n=1, default=0)))\nacf(residuals)"},{"path":"optCchangepoint.html","id":"savings","chapter":"4 Tutorial 2: change-point model","heading":"4.4 Savings","text":"Stan model already calculates expected output \\(y\\) reporting period, sample \\(\\theta_i\\) posterior distribution. can therefore display probability distribution data points reporting period, compare measured data period.following graph compares energy use measured reporting period (points) probability distributions energy use predicted model period.\nsavings, .e. difference measured energy use reporting period prediction model, included Stan model definition. Similarly prediction, savings therefore available probability distribution: full description confidence interval may wish .table results shown model fitting shows thatThe mean estimated savings 69,069 kWhThe 95% confidence interval spans 63,550 74,880 kWhWe can also choose display quantile posterior distribution savings:However savings estimate may biased. autocorrelated residuals suggest ","code":"\n# Extracting full predictive distributions from the stanfit object\ny_repo_pred <- la$y_repo_pred\n# Quantiles\ny_repo_quan <- apply(y_repo_pred, 2, quantile, probs=c(0.025, 0.5, 0.975))\n# Data frame\ndf.repo.daily <- df.repo.daily %>% mutate(pred_low = y_repo_quan[1, ],\n                                          pred_med = y_repo_quan[2, ],\n                                          pred_up = y_repo_quan[3, ])\n# Plot\nggplot(data = df.repo.daily) +\n  geom_point(mapping = aes(x=T, y=E)) +\n  geom_line(mapping = aes(x=T, y=pred_med), color='red') +\n  geom_ribbon(mapping = aes(x=T, ymin=pred_low, ymax=pred_up), fill='red', alpha=0.1)\nplot(fit1, pars = c(\"savings\"))## ci_level: 0.8 (80% intervals)## outer_level: 0.95 (95% intervals)"},{"path":"optCautocorr.html","id":"optCautocorr","chapter":"5 Tutorial 3: autocorrelation","heading":"5 Tutorial 3: autocorrelation","text":"click interactive version tutorialThis follow-tutorial 2 explain autocorrelation deal .fitted model autocorrelated residuals, two options :possible, improve model better description building physics;possible improve model , data insufficient learn additional parameters, autocorrelation remains, can somehow “include ” model.latter accounts accepting reached ceiling model refinement, making reliable predictions come cost increased uncertainty.Consider general model formulation observed variable (energy use) \\(y\\) time \\(t\\) expected\\[\ny_t = f(T_t, occ_t) + \\varepsilon_t\n\\]\\(f\\) can function observed variables (ambient temperature, occupancy, etc.)moving average (MA) model uses previous errors predictors future outcomes (see Stan documentation). MA model order \\(Q\\), \\(\\mathrm{MA}(Q)\\) add regression coefficients \\(\\theta_q\\) previous error terms.\\[\ny_t = f(T_t, occ_t) + \\theta_1 \\varepsilon_{t-1} + \\dots + \\theta_Q \\varepsilon_{t-Q} + \\varepsilon_t\n\\]see Stan doc moving average models: https://mc-stan.org/docs/stan-users-guide/moving-average-models.htmlThis model much harder time converging. obtain good mixing high warmupARIMA prediction intervals : see https://otexts.com/fpp2/arima-forecasting.html\\[\n\\hat{\\sigma}_h=\\hat{\\sigma}^2 \\left[1+\\sum_{=1}^{h-1}\\hat{\\theta}_i^2\\right]\n\\]","code":"\nlibrary(rstan)\nlibrary(tidyverse)\nlibrary(lubridate)\n# Baseline data: one year\ndf.pre <- read_csv(\"data/Long-term 11 commercial buildings/building60preoffice.csv\") %>% \n  mutate(DateTime = mdy_hm(Date),\n         Date = as_date(DateTime))\n\n# Post-retrofit data: one year\ndf.post <- read_csv(\"data/Long-term 11 commercial buildings/building61duringoffice.csv\") %>% \n  mutate(DateTime = mdy_hm(Date),\n         Date = as_date(DateTime))\n\n# Plot the original data\nhead(df.pre)## # A tibble: 6 x 4\n##   Date         OAT `Building 6 kW` DateTime           \n##   <date>     <dbl>           <dbl> <dttm>             \n## 1 2009-01-02  41.6            23.3 2009-01-02 00:00:00\n## 2 2009-01-02  40.9            23.1 2009-01-02 01:00:00\n## 3 2009-01-02  39.5            23.7 2009-01-02 02:00:00\n## 4 2009-01-02  36.3            29.1 2009-01-02 03:00:00\n## 5 2009-01-02  32.8            35.6 2009-01-02 04:00:00\n## 6 2009-01-02  32.5            45.5 2009-01-02 05:00:00\nggplot(data = df.pre) + geom_line(mapping = aes(x=DateTime, y=`Building 6 kW`))\ndaily.average <- function(df) {\n  df %>% \n    group_by(Date) %>% \n    summarise(OAT = mean(OAT),\n              E = sum(`Building 6 kW`),\n              .groups = 'drop'\n    ) %>% \n    mutate(wday = wday(Date),\n           week.end = wday==1 | wday==7,\n           T = (OAT-32) * 5/9)\n}\n\ndf.pre.daily <- daily.average(df.pre)\ndf.post.daily <- daily.average(df.post)\n\nggplot(data = df.pre.daily) +\n  geom_point(mapping = aes(x=T, y=E, color=week.end))\ndf.pre.daily <- daily.average(df.pre) %>% filter(!week.end)\ndf.post.daily <- daily.average(df.post) %>% filter(!week.end)\nchangepoint <- [2239 chars quoted with '\"']\nmodel_data <- list(\n  N_pre = nrow(df.pre.daily),\n  t_pre = df.pre.daily$T,\n  y_pre = df.pre.daily$E,\n  N_post = nrow(df.post.daily),\n  t_post = df.post.daily$T,\n  y_post = df.post.daily$E\n)\n# Fitting the model\nfit1 <- stan(\n  model_code = changepoint,  # Stan program\n  data = model_data,        # named list of data\n  chains = 4,               # number of Markov chains\n  warmup = 4000,            # number of warmup iterations per chain\n  iter = 6000,              # total number of iterations per chain\n  cores = 2,                # number of cores (could use one per chain)\n  refresh = 1,              # progress not shown\n)\nprint(fit1, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"theta\", \"savings\"))## Inference for Stan model: dc86eba33ef72f3cda80b6310ccd1c15.\n## 4 chains, each with iter=6000; warmup=4000; thin=1; \n## post-warmup draws per chain=2000, total post-warmup draws=8000.\n## \n##             mean se_mean      sd     2.5%      25%      50%      75%    97.5%\n## alpha     829.07    0.17   13.80   802.10   819.67   829.15   838.51   855.72\n## beta_h     32.02    0.03    2.65    27.01    30.18    31.94    33.79    37.38\n## tau_h       6.75    0.01    0.81     5.28     6.12     6.77     7.33     8.33\n## beta_c     26.57    0.04    2.66    21.90    24.73    26.41    28.23    32.40\n## tau_c      15.00    0.01    0.98    13.17    14.33    14.91    15.61    17.09\n## sigma      78.07    0.04    3.29    72.14    75.78    77.90    80.19    84.91\n## theta       0.57    0.00    0.04     0.49     0.55     0.57     0.60     0.65\n## savings 46837.58   26.94 2484.02 41994.69 45162.18 46826.40 48492.74 51690.53\n##         n_eff Rhat\n## alpha    6759    1\n## beta_h   6117    1\n## tau_h    5055    1\n## beta_c   5536    1\n## tau_c    4935    1\n## sigma    8701    1\n## theta    6123    1\n## savings  8504    1\n## \n## Samples were drawn using NUTS(diag_e) at Fri Mar 24 13:40:00 2023.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\ntraceplot(fit1, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"lp__\"))\npairs(fit1, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"theta\"))\n# Extracting full predictive distributions from the stanfit object\nla <- rstan::extract(fit1, permuted = TRUE)\ny_pre_pred <- la$y_pre_pred\n\n# Quantiles\ny_pre_quan <- apply(y_pre_pred, 2, quantile, probs=c(0.025, 0.5, 0.975))\n\n# Adding prediction quantiles to the baseline dataframe\ndf.pre.daily <- df.pre.daily %>% mutate(pred_low = y_pre_quan[1, ],\n                                          pred_med = y_pre_quan[2, ],\n                                          pred_up = y_pre_quan[3, ])\n\n# Plot\nggplot(data = df.pre.daily) +\n  geom_point(mapping = aes(x=T, y=E)) +\n  geom_line(mapping = aes(x=T, y=pred_med), color='red') +\n  geom_ribbon(mapping = aes(x=T, ymin=pred_low, ymax=pred_up), fill='red', alpha=0.1)\nggplot(data = df.pre.daily) +\n  geom_line(mapping = aes(x=Date, y=pred_med-E)) +\n  geom_ribbon(mapping = aes(x=Date, ymin=pred_low-E, ymax=pred_up-E), alpha=0.2)\nresiduals <- colMeans(la$y_pre_pred) - df.pre.daily$E\n\nggplot() +\n  geom_point(mapping = aes(x=residuals, y=lag(residuals, n=1, default=0)))\nggplot() +\n  geom_point(mapping = aes(x=residuals, y=lag(residuals, n=2, default=0)))\nacf(residuals)"},{"path":"optDbasics.html","id":"optDbasics","chapter":"Option D basics","heading":"Option D basics","text":"Just essentials.","code":""},{"path":"bayesian-calibration.html","id":"bayesian-calibration","chapter":"6 Bayesian calibration","heading":"6 Bayesian calibration","text":"literature principles “bayesian calibration”, Option D can done bayesically.","code":""}]
