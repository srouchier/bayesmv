[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"website promotes use Bayesian data analysis building energy use monitoring, especially context Measurement Verification (M&V) methods.target audience book energy experts may moderate background statistics applied mathematics. One main arguments promoting Bayesian data analysis universally applicable, accessible. aim give building energy practicioners tools reliably assess savings following energy conservation measures, along uncertainty.guide assumes reader already knows core statistical concepts M&V: errors uncertainty, regression basics, model validation metrics. however emphasise terms order illustrate specifics Bayesian methods.first part website introduces reader main concepts measurement verification, Bayesian data analysis. amount theoretical background voluntarily kept short order keep focus practical examples. References included readers wish learn .second part tutorials whole-building energy monitoring M&V, referred “Option C” IPMVP documentation. series three tutorials gradually illustrate advantages Bayesian data analysis M&V:first tutorial serves introduction Stan platform, shows Bayesian analysis obtains uncertainty assessments classical methods, analytical solutions available.reader reassured accuracy method, second tutorial shows effortlessly extends complex model structures, analytical solutions may longer evaluate uncertainty analytically.third tutorial addresses issue residuals autocorrelation, often arises model calibration. show overcome issue Bayesian models.third part website still construction address IPMVP Option D -called Bayesian calibration building energy models.","code":""},{"path":"index.html","id":"the-content-and-how-to-use-it","chapter":"Welcome","heading":"The content and how to use it","text":"content displayed R notebooks allow displaying full code calculations, results explanations. order apply methods use cases, first:Install R RstudioInstall Stan.use R Stan analyses, content also adaptable environments reader may familiar : Python, Julia Matlab. mention alternatives .Additionally, wish replicate results shown tutorials, may either download full book repository run R markdown files matching chapters; download data sets copy/paste code R files.","code":""},{"path":"index.html","id":"about","chapter":"Welcome","heading":"About","text":"Simon Rouchier, lecturer Université Savoie Mont Blanc, Chambéry, France.Ce(tte) œuvre est mise à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International.","code":""},{"path":"back-mv.html","id":"back-mv","chapter":"1 Measurement and verification","heading":"1 Measurement and verification","text":"chapter next one excerpts author’s larger website building energy statistical modelling.","code":""},{"path":"back-mv.html","id":"intro-to-mv-and-the-ipmvp","chapter":"1 Measurement and verification","heading":"1.1 Intro to M&V and the IPMVP","text":"Measurement Verification (M&V) process assessing savings caused Energy Conservation Measure (ECM). M&V crucial tool establishment Energy Performance Contracts (EPC), can established basis designed performance (building energy simulation), eventual uncertainty analysis /sensitivity analysis, basis measured energy consumption.International Performance Measurement Verification Protocol (IPMVP) formalizes process, presents several options conduct . Savings determined comparing measured consumption demand implementation program, making suitable adjustments changes conditions.example adjustment , estimating energy savings delivered ECM, substract new energy consumption consumption occurred building stayed situation weather conditions reporting period (adjusted baseline consumption). requires prediction model can extrapolate initial behaviour building accounting variable weather conditions. possible adjustments include changes occupancy schedules. necessary assess whether measured energy savings caused ECM , changes influences.\nFigure 1.1: IPMVP provides guidelines perform M&V\n“avoided energy consumption” approach, savings reported conditions reporting (post-retrofit) period. Alternatively, “normalized savings” approach, savings calculated separate set conditions, requires fitting separate models pre- post-ECM periods, comparing predictions new conditions.IPMVP presents several options, depending whether operation concerns entire facility portion, defines notion measurement boundary set measurements relevant determine savings (see Sec. 1.2 ).order verify savings single equipment, measurement boundary can drawn around , approach used retrofit-isolation: IPMVP options B.purpose reporting verify total facility energy performance, approach whole-facility option C.IPMVP option D, savings determined simulation pre-ECM energy consumption rather direct measurements. simulation model calibrated predicts energy load matches post-ECM metered data.","code":""},{"path":"back-mv.html","id":"boundaries","chapter":"1 Measurement and verification","heading":"1.2 Measurement and modelling boundaries","text":"M&V options rely definition numerical model reproduces relationship variables monitored measurement boundary.dependent variable \\(y\\), model output, variable wish fitted model able predict.explanatory variables, independent variables, model inputs try explain evolutions dependent variable. Explanatory variables denoted \\(x\\) regression models, \\(u\\) complex hierarchical models \\(x\\) may denote latent variable instead.models latent variables, unobserved affect dependent variable.IPMVP defines measurement boundaries “notional boundaries drawn around equipment, systems facilities segregate relevant saving determination . Energy Consumption Demand equipment systems within boundary must measured estimated. […] energy effects occurring beyond selected measurement boundary called interactive effects. magnitude interactive effects needs estimated evaluated determine savings associated ECMs.”definition boundaries work simulations: model must defined inputs outputs measured independent dependent variables, energy effects occurring within boundaries either fixed, part list parameters \\(\\theta\\) estimated calibration.\nFigure 1.2: Building energy models simulate interactions envelope, ambiance, HVAC systems controls, described finite set parameters. explanatory variables related two conditions mentioned earlier: weather occupants. dependent variables separate energy consumptions.\nTypical modelling boundaries building energy simulation (BES) resemble Fig. 1.2. time-varying inputs provided user weather files occupancy profiles. time, latter come standard scenarios rather measurement. Occupancy understood BES finite set actions influences: presence, temperature set-points, use appliances. model returns predictions energy use, usually higher level disaggregation (consumption system) easily available measurement.","code":""},{"path":"back-mv.html","id":"back-stats","chapter":"1 Measurement and verification","heading":"1.3 Error and uncertainty","text":"Inverse problem theory can summed science training models using measurements. target training either learn physical properties system indirect measurements, setting predictive model can reproduce past observations.general principle solving system identification problem describe observed phenomenon model allowing simulation. Measurements \\((\\mathbf{x},\\mathbf{y})\\) carried experimental setup: building probed quantities wish estimate energy performance (indoor temperature, meter readings, climate, etc.) model defined mapping measurements set input \\(\\mathbf{x}\\) (boundary conditions, weather data) output \\(\\mathbf{y}\\). numerical model mathematical formulation outputs \\(f(x, \\theta)\\), parameterised finite set variables \\(\\theta\\). intuitive way calibrate model minimize indicator sum squared residuals, order find value \\(\\theta\\) makes model closely match data.Ideally, model unbiased: accurately describes behaviour system, exists true value \\(\\theta^*\\) parameter vector model output reproduces undisturbed value observed variables.\n\\[\\begin{equation}\ny_k = f(x_k, \\theta^*) + \\varepsilon_k\n\\tag{1.1}\n\\end{equation}\\]\n\\(\\varepsilon\\) denotes measurement error, .e. difference real process observed value \\(y\\). convenient assumption additive noise, .e. \\(\\varepsilon_k\\) sequence independent identically distributed random variables.practice, \\(\\theta^*\\) never reached exactly, rather approached estimator \\(\\hat \\theta\\), entire process estimating measurements disturbed array approximations:Experimental errors. numerical data \\((x,y)\\) available model calibration differs hypothetical outcome ideal, undisturbed physical system. Sensors may intrusive, produce noisy measurements, may poorly calibrated, finite precision resolution…Numerical errors. hypothesis unbiased model (Eq. (1.1)) states exists parameter value \\(\\theta^*\\) model output separated observations \\(y\\) zero mean, Gaussian distributed measurement noise. means model perfectly reproduces physical reality, perceptible error due imperfection sensors. exceedingly optimistic, especially building energy simulation.\nFigure 1.3: Errors uncertainties parameter estimation, caused measurement modelling errors\nGuide expression Uncertainty Measurement (GUM)(JCGM (2008)) separates errors random component systematic component: systematic errors errors retain non-zero mean measurement repeated infinite number times repeatability conditions. Systematic random errors, whether concern measurement modelling procedures, affect estimation parameter \\(\\theta\\) terms accuracy precision. figure illustrates accuracy precision case estimating parameter value \\(\\theta\\), exact terminology can used purpose trained model predict future values variable \\(y\\).GUM defines uncertainty (measurement) dispersion values reasonably attributed measured quantity. Similarly, parameter estimates model predictions come uncertainty, quantifies possible range values caused random errors measurement modelling processes. Precision indicator low uncertainty, can conveyed confidence intervals.hand, accuracy measure bias. difference “true” value target variable mean estimation.Biased estimates predictions outcome errors explicitely taken account inverse problem. tend prefer low bias high uncertainty, high bias low uncertainty: indeed, high uncertainty suggests data sufficient provide confident inferences, incites caution communicating results.description bias uncertainty applies value estimated model parameters, predictions subsequently performed fitted model. particular, concerns estimation savings based energy use predictions: end goal obtain reliable (unbiased) inference energy savings uncertainty. motivation guide show Bayesian methods well suited goal.","code":""},{"path":"back-bayes.html","id":"back-bayes","chapter":"2 Bayesian data analysis","heading":"2 Bayesian data analysis","text":"chapter covers basics Bayesian inference, motivation behind choice use practice. internet lot reading material matter wish go .Gelman et al’s book Bayesian data analysis, aka Big Bayesian Book, covers every aspect vast field example-oriented.Bayesian workflow data analysis practical summary, although still comprehensive.Statistical rethinking another vast Bayesian course spanning theoretical fundamentals practical examples.Michael Betancourt’s extensive lectures range basics probability theory extremely detailed Bayesian workflow.","code":""},{"path":"back-bayes.html","id":"motivation","chapter":"2 Bayesian data analysis","heading":"2.1 Motivation for a Bayesian M&V","text":"Bayesian statistics mentioned Annex B ASHRAE Guideline 14, observed standard approaches make difficult estimate savings uncertainty complex models required measurement verification worflow:“Savings uncertainty can determined exactly energy use linear function independent variable(s). complicated models energy use, changepoint models, data serially autocorrelated errors, approximate formulas must used. approximations provide reasonable accuracy compared simulated data, general difficult determine accuracy given situation. One alternative method determining savings uncertainty desired degree accuracy use Bayesian approach.”Still topic measurement verification, estimation savings uncertainty, several advantages drawbacks Bayesian approaches described (Carstens, Xia, Yadavalli (2018)). Advantages include:Bayesian models probabilistic, uncertainty automatically exactly quantified. Confidence intervals can interpreted way people understand : degrees belief value parameter.Bayesian models universal flexible standard methods. Models also modular can designed suit problem. example, different create terms serial correlation, heteroscedasticity (non-constant variance) specify ordinary linear model.Bayesian approach allows incorporation prior information appropriate.savings need calculated “normalised conditions”, example, “typical meteorological year”, rather conditions post-retrofit monitoring period, possible quantify uncertainty using current methods. However, (Shonder Im (2012)) shown can naturally easily quantified using Bayesian approach.first two points relevant data analyst: arbitrary model structure can defined explain data, exact set formulas can used obtain uncertainty models fitted.","code":""},{"path":"back-bayes.html","id":"bayesian-inference-in-theory","chapter":"2 Bayesian data analysis","heading":"2.2 Bayesian inference in theory","text":"Bayesian model defined two components:observational model \\(p\\left(y|\\theta\\right)\\), likelihood function, describes relationship data \\(y\\) model parameters \\(\\theta\\).prior model \\(p(\\theta)\\) encodes eventual assumptions regarding model parameters, independently observed data. Specifying prior densities mandatory.target Bayesian inference estimation posterior density \\(p\\left(\\theta|y\\right)\\), .e. probability distribution parameters conditioned observed data. consequence Bayes’ rule, posterior proportional product two previous densities:\\[\\begin{equation}\np(\\theta|y) \\propto p(y|\\theta) p(\\theta)\n\\tag{2.1}\n\\end{equation}\\]formula can interpreted follows: posterior density compromise assumptions evidence brought data. prior can “strong” “weak”, reflect less confident prior knowledge. posterior stray away prior data introduced.\nFigure 2.1: Example estimating set point temperature assuming Normal prior distribution centred around 20°C. dashed line point estimate obtained data considered. posterior distribution can seen “refinement” prior, given evidence data.\ngeneral, information posterior distribution represented summary statistics mean, variance credible intervals, can used inform decisions easier interpret full posterior distribution. summary statistics take form posterior expectation values certain functions, \\(f(\\theta)\\),\\[\\begin{equation} \\label{posterior_expectation}\n    \\mathbb{E}[f(\\theta)] = \\int p(\\theta|y) f(\\theta) \\mathrm{d} \\theta\n    \\tag{2.2}\n\\end{equation}\\]sophisticated questions answered expectation values custom functions \\(f(\\theta)\\). One common example posterior predictive distribution: many applications, one interested estimating parameter values, also predictions \\(\\tilde{y}\\) observable new period. distribution \\(\\tilde{y}\\) conditioned observed data \\(y\\) called posterior predictive distribution:\\[\\begin{equation}\np\\left(\\tilde{y}|y\\right) = \\int p\\left(\\tilde{y}|\\theta\\right) p\\left(\\theta|y\\right) \\mathrm{d}\\theta\n\\tag{2.3}\n\\end{equation}\\]posterior predictive distribution average model predictions posterior distribution \\(\\theta\\). formula equivalent concept using trained model prediction.Apart possibility define prior distributions, main specificity Bayesian analysis fact variables encoded probability densities. two main results, parameter posterior \\(p(\\theta|y)\\) posterior prediction \\(p\\left(\\tilde{y}|y\\right)\\), point estimates complete distributions include full description uncertainty.","code":""},{"path":"back-bayes.html","id":"a-bayesian-data-analysis-workflow","chapter":"2 Bayesian data analysis","heading":"2.3 A Bayesian data analysis workflow","text":"section excerpt author’s larger website building energy statistical modelling.","code":""},{"path":"back-bayes.html","id":"overview","chapter":"2 Bayesian data analysis","heading":"2.3.1 Overview","text":"mentioned Sec. 1.3, inverse problems trivial. possible available data simply insufficient bring useful inferences, still try train unsuitable model . Statistical analysts need right tools guide model selection training, warn risk biased inferences predictions.chapter attempt summarize essential points Bayesian workflow building energy perspective. Frequentist inference also mentioned, particular case Bayesian inference.Gelman et al. (Gelman et al. (2013)) divide process Bayesian data analysis three steps illustrated Fig. 2.2:Setting full probability model;Conditioning observed data (learning);Evaluating fit model implications resulting posterior (checking validation).\nFigure 2.2: workflow proper specification training one model. workflow similar frequentist Bayesian inference.\n","code":""},{"path":"back-bayes.html","id":"step-1-model-specification","chapter":"2 Bayesian data analysis","heading":"2.3.2 Step 1: model specification","text":"first step building model conceptual analysis system available data. first question decide want learn data, related choice measurement modelling boundaries mentioned Sec. 1.2, choice model structure: measurements dependent variable \\(y\\), relevant explanatory variables \\(x\\), model parameters \\(\\theta\\) defined.model definition greatly impacted time resolution length dataset. Higher time resolutions (hour) enable choice dynamical models, can encode inferential information imply complex development. Longer datasets (several months) enable aggregation data longer resolutions observations covering different weather conditions.next step development model: translation conceptual narrative system formal mathematical descriptions. target formulate entire system probabilities fitting method can work . case simple regression models, observational model may summarized single likelihood function \\(p(y|\\theta)\\), eventually conditioned explanatory variables.practitioner wishes use regression model explain relationship parameters data, Bayesian framework similar usual (frequentist) framework. example, Bayesian model linear regression three parameters \\((\\theta_0,\\theta_1,\\theta_2)\\) two explanatory variables \\((X_1,X_2)\\) may read:\n\\[\\begin{align}\n    p(y|\\theta,X) & = N\\left(\\theta_0 + \\theta_1 X_1 + \\theta_2 X_2, \\sigma\\right) \\tag{2.4} \\\\\n    p(\\theta_i) & = \\Gamma(\\alpha_i, \\beta_i) \\tag{2.5}\n\\end{align}\\]means \\(y\\) follows Normal distribution whose expectation linear function \\(\\theta\\) \\(X\\), standard deviation \\(\\sigma\\) (measurement error). second equation prior model: example, parameter assigned Gamma prior distribution parameterised shape \\(\\alpha\\) scale \\(\\beta\\). model structures can formulated similarly: change-point models, polynomials, models categorical variables… Bayesian modelling however allows much flexibility:distributions Normal distribution can used observational model;Hierarchical modelling possible: parameters can assigned prior distribution parameters (hyper)prior distribution;Heteroscedasticity can encoded assuming relationship error term explanatory variables, etc.complex models latent variables separate expressions respective conditional probabilities observations \\(y\\), latent variables \\(z\\) parameters \\(\\theta\\). case, likelihood function \\(p(y,z|\\theta)\\) marginal likelihood function \\(p(y|\\theta)\\) :\n\\[\\begin{equation}\n    p(y|\\theta) = \\int p(y,z|\\theta) \\mathrm{d}z\n    \\tag{2.6}\n\\end{equation}\\]IPMVP option D relies use calibrated building energy simulation (BES) models. models described much larger number parameters equations simple regression models typically used IPMVP options. context, feasible fully describe BES models form simple likelihood function \\(p(y|\\theta)\\). order apply Bayesian uncertainty analysis BES model, possible first approximate Gaussian process (GP) model emulator. process denoted Bayesian calibration based seminal work Kennedy O’Hagan (Kennedy O’Hagan (2001)). opposed manual adjustment building energy model parameters, Bayesian calibration explicitly quantifies uncertainties calibration parameters, discrepancies model predictions observed values, well observation errors (Chong Menberg (2018)).","code":""},{"path":"back-bayes.html","id":"priorpredictivechecking","chapter":"2 Bayesian data analysis","heading":"2.3.3 Prior predictive checking","text":"full probability model formalization many assumptions regarding data-generating process. theory, model can formulated based domain expertise, regardless data. practice, model inconsistent data little chance yield informative inferences training. prior predictive distribution, marginal distribution observations \\(p(y)\\), way check consistency expertise.\\[\\begin{equation}\np\\left(y\\right) = \\int p\\left(y|\\theta\\right) p\\left(\\theta\\right) \\mathrm{d}\\theta\n\\tag{2.7}\n\\end{equation}\\]Basically, computing distribution equivalent running simulations numerical model training, assumed values parameters. Bayesian terms, first draw finite number parameter vectors \\(\\tilde{\\theta}^{(m)}\\) prior distribution, use compute model output \\(\\tilde{y}^{(m)}\\):\\[\\begin{align}\n    \\tilde{\\theta}^{(m)} & \\sim p(\\theta) \\tag{2.8} \\\\\n    \\tilde{y}^{(m)} & \\sim p(y|\\tilde{\\theta}^{(m)})\n    \\tag{2.9}\n\\end{align}\\]set model outputs approximates prior probability distribution. large inconsistencies can spotted distribution measurements, can adjust assumptions regarding prior definition structure observational model. example prior predictive checking shown top right Fig. 2.2, suggests model structures contradict observations.","code":""},{"path":"back-bayes.html","id":"computation","chapter":"2 Bayesian data analysis","heading":"2.3.4 Step 2: computation with Markov Chain Monte Carlo","text":"Except convenient situations, posterior distribution analytically tractable. practice, rather finding exact solution , estimated approximate methods. popular option approximate posterior inference Markov Chain Monte Carlo (MCMC) sampling methods. possible computationally efficient sample directly posterior distribution, Markov Chain simulation used stochastically explore typical set, .e. regions parameter space significant contribution desired expectations. Markov chains used MCMC methods designed stationary distribution posterior distribution. chain long enough, state history chain provides samples typical set \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)\\)\n\\[\\begin{equation}\n    \\theta^{(s)} \\sim p(\\theta | y)\n    \\tag{2.10}\n\\end{equation}\\]\ndraw \\(\\theta^{(s)}\\) contains value parameters model.guide aim explaining MCMC algorithms characteristics, may refer paper (Betancourt (2017)) description state---art Hamiltonian Monte Carlo alogrithm.Posterior expectation values can accurately estimated Monte Carlo estimator. Based exact independent random samples posterior distribution \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right) \\sim p(\\theta | y)\\), expectation function \\(f(\\theta)\\) can estimated \n\\[\\begin{equation}\n    \\mathbb{E}[f(\\theta)] \\approx\n    \\frac{1}{N} \\sum_{n=1}^{N} f(\\theta)^{(n)}\n\\tag{2.11}\n\\end{equation}\\]Markov Chain Monte Carlo estimators converge true expectation values number draws approaches infinity. practice, diagnostics must applied check estimator follows central limit theorem, ensures estimator unbiased finite number draws. purpose first recommended compute (split-)\\(\\hat{R}\\) statistic, Gelman-Rubin statistic, multiple chains initialized different initial positions split two halves (Gelman et al. (2013)). \\(\\hat{R}\\) statistic measures scalar parameter, \\(\\theta\\), ratio samples variance within chain \\(W\\) sample variance combined chains \\(B\\),\\[\\begin{equation}\n    \\hat{R} = \\sqrt{\\frac{1}{W} \\left(\\frac{N-1}{N}W + \\frac{1}{N}B \\right)}\n    \\tag{2.12}\n\\end{equation}\\]\\(N\\) number samples. chains converged, \\(W\\) underestimate variance, since individual chains time range stationary distribution, \\(B\\) overestimate variance, since starting positions chosen overdispersed.Another important convergence diagnostics tool effective sample size (ESS), defined :\\[\\begin{equation}\n    \\text{ESS} = \\frac{N}{1 + 2 \\sum_{l=1}^{\\infty} \\rho_l}\n    \\tag{2.13}\n\\end{equation}\\]\\(\\rho_l\\) lag-\\(l\\) autocorrelation function \\(f\\) history Markov chain. effective sample size estimate number independent samples posterior distribution.diagnostic tools introduced section provide principled workflow reliable Bayesian inferences. readily available Bayesian computation libraries. Based recent improvements \\(\\hat{R}\\) statistic (Vehtari et al. (2021)), recommended use samples \\(\\hat{R} < 1.01\\) \\(\\text{ESS} > 400\\).","code":""},{"path":"back-bayes.html","id":"modelvalidation","chapter":"2 Bayesian data analysis","heading":"2.3.5 Step 3: model checking and validation","text":"model specification learning, third step workflow model checking validation. conducted conclusions drawn, prediction accuracy model estimated.posterior predictive distributionThe basic way checking fit model data draw simulated values trained model compare observed data. non-Bayesian framework, pick likely point estimate parameters, maximum likelihood estimate, use compute model output \\(\\hat{y}\\), conduct residual analysis. Bayesian framework, posterior predictive checking allows possibilities.posterior predictive distribution distribution observable \\(\\tilde{y}\\) (model output) conditioned observed data \\(y\\):\n\\[\\begin{equation}\np\\left(\\tilde{y}|y\\right) = \\int p\\left(\\tilde{y}|\\theta\\right) p\\left(\\theta | y\\right) \\mathrm{d}\\theta\n\\tag{2.14}\n\\end{equation}\\]\ndefinition similar prior predictive distribution given Sec. 2.3.3, except prior \\(p(\\theta)\\) replaced posterior \\(p(\\theta|y)\\). Similarly, simple compute posterior approximated MCMC procedure: first draw finite number parameter vectors \\(\\theta^{(m)}\\) posterior distribution, use compute model output \\(\\tilde{y}^{(m)}\\):\n\\[\\begin{align}\n    \\theta^{(m)} & \\sim p(\\theta|y) \\tag{2.15}\\\\\n    \\tilde{y}^{(m)} & \\sim p(y|\\theta^{(m)})\n    \\tag{2.16}\n\\end{align}\\]\nset model outputs approximates posterior probability distribution.following methods model checking may apply either frequentist Bayesian framework.fitting returns point estimate parameters \\(\\hat{\\theta}\\), single profile model output \\(\\hat{y}\\) can calculated , either compared training data set \\(y_\\mathit{train}\\) separate test data set \\(y_\\mathit{test}\\).fitting returns point estimate parameters \\(\\hat{\\theta}\\), single profile model output \\(\\hat{y}\\) can calculated , either compared training data set \\(y_\\mathit{train}\\) separate test data set \\(y_\\mathit{test}\\).fitting returns posterior distribution \\(p(y|\\theta)\\), comparisons may applied \\(\\tilde{y}^{(m)}\\) samples.fitting returns posterior distribution \\(p(y|\\theta)\\), comparisons may applied \\(\\tilde{y}^{(m)}\\) samples.Measures model adequacyMeasures model adequacyAfter fitting, either ordinary linear regression sophisticated ones, metrics may assess predictive accuracy model.R-squared (\\(R^2\\)) index proportion variance dependent variable explained regression model (closest 1 better)\\[\\begin{equation}\n    R^2 = 1-\\frac{\\sum_{=1}^N\\left(y_i - \\hat{y}_i\\right)^2}{\\sum_{=1}^N\\left(y_i - \\bar{y}_i\\right)^2}\n    \\tag{2.17}\n\\end{equation}\\]root-mean-square-error (RMSE) simply measures differences model predictions \\(\\hat{y}\\) observations \\(y\\) (lower better)\\[\\begin{equation}\n\\mathrm{CV(RMSE)} = \\frac{1}{\\bar{y}} \\sqrt{\\frac{\\sum_{=1}^N\\left(\\hat{y}_i-y_i\\right)^2}{N}}\n\\tag{2.18}\n\\end{equation}\\]Coverage Width-based Criterion (CWC) (Chong, Augenbroe, Yan (2021)), indicator probabilistic forecasts measures quality predictions based accuracy precision.\\(R^2\\) CV-RMSE indices often treated validation metrics. calculated using test data set, can indeed estimate model predictive ability outside training data set. however ensure model correctly captures data generating process: residual analysis .Residual analysis hypothesis unbiased model assumes difference model output observed temperature sequence independent, identically distributed variables following Gaussian distribution zero mean constant covariance. example linear regression model, condition may read:\n\\[\\begin{equation}\n    r_i = y_i - \\left( \\hat{\\theta}_0 + \\hat{\\theta}_1 X_{,1} + \\hat{\\theta}_2 X_{,2} \\right) \\sim N(0,\\sigma)\n    \\tag{2.19}\n\\end{equation}\\]\n\\(r_i\\) prediction residuals. Residual analysis process checking validity four hypotheses (independence, identical distribution, zero mean, constant variance), main step model validation. allows identifying problems may arise fitting regression model (James et al. (2013)), among : correlation error terms, outliers, high leverage points, colinearity…\nFigure 2.3: Example residual plots ordinary linear regression R: fitted vs residuals, Q-Q plot, scale location residuals vs leverage\nResidual analysis can performed array tests graphs, shown Fig. 2.3.simple plot residuals versus model output display trend. goes plot residuals vs explanatory variables. trend visible, model structure probably insufficient explain data.quantile-quantile (Q-Q) plot (upper right) way check distribution residuals approximately GaussianThe scale-location plot (lower left) way check hypothesis homoskedasticity, .e. constant varianceThe residuals vs leverage plot (lower right) allows identifying eventual outliers high leverage points.\nFigure 2.4: Autocorrelation function (top) cumulated periodogram (bottom) insufficient model (left) sufficient model (right)\nimportantly, correlation among error terms checked. autocorrelation function (ACF) checks independence residuals may reveal lag dependencies suggest influences model properly take account. particularly important time series models, therefore well explained time series litterature (Shumway Stoffer (2000)). Alternatively, Durbin-Watson test quantitatively checks autocorrelation regression models. “correlation among error terms, estimated standard errors tend underestimate true standard errors. result, confidence prediction intervals narrower .”(James et al. (2013))residuals display unequal variances correlations, inferences predictions fitted model used. model modified re-trained according practitioner’s expertise diagnostics analysis: additional explanatory variables can included possible.","code":""},{"path":"back-bayes.html","id":"bayesian-mv-in-practice","chapter":"2 Bayesian data analysis","heading":"2.4 Bayesian M&V in practice","text":"","code":""},{"path":"back-bayes.html","id":"estimating-savings-and-their-uncertainty","chapter":"2 Bayesian data analysis","heading":"2.4.1 Estimating savings and their uncertainty","text":"following workflows M&V can followed regardless chosen type model (regression model options , B C, GP emulator option D). choice workflow mostly depend availability data baseline reporting periods.\nFigure 2.5: Estimation savings uncertainty avoided consumption workflow. step model validation displayed.\nsummary workflow estimate savings uncertainty, following reporting period basis, avoided energy consumption. assume measurement boundaries defined data \\(y_\\mathit{base}\\) \\(y_\\mathit{repo}\\) recorded baseline reporting period respectively.standard approaches, choose model structure describe data , formulate likelihood function. Formulate eventual “expert knowledge” assumptions form prior probability distributions.Run MCMC () algorithm obtain set samples \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)\\) approximates posterior distribution parameters conditioned baseline data \\(p\\left(\\theta | y_\\mathit{base}\\right)\\). Validate inference checking convergence diagnostics: R-hat, ESS, etc.Validate model computing predictions baseline period \\(p\\left(\\tilde{y}_\\mathit{base} | y_\\mathit{base}\\right)\\). can done taking (representative set ) samples \\(\\theta^{(s)}\\) individually, running model simulation \\(\\tilde{y}_\\mathit{base}^{(s)} \\sim p\\left(y_\\mathit{base} | \\theta=\\theta^{(s)}\\right)\\) . set simulations generates posterior predictive distribution baseline period, statistic can derived (mean, median, prediction intervals quantile, etc.). measures model validation (R-squared, net determination bias, t-statistic…) can computed either mean, samples order obtain probability densities.Compute reporting period predictions discrete way: sample \\(\\theta^{(s)}\\) generates profile \\(\\tilde{y}_\\mathit{repo}^{(s)} \\sim p\\left(y_\\mathit{repo} | \\theta=\\theta^{(s)}\\right)\\), set simulations generates posterior predictive distribution reporting period.Since reporting period prediction \\(\\tilde{y}_\\mathit{repo}^{(s)}\\) can compared measured reporting period consumption \\(y_\\mathit{repo}\\), can obtain S values energy savings, distribution approximate posterior probability savings.\\[\\begin{align}\n\\Delta e^{(s)} & = \\sum_{=1}^n\\left(\\tilde{y}_\\mathit{repo}^{(s)}()-y_\\mathit{repo}()\\right) \\tag{2.19} \\\\\n& \\sim p\\left(\\Delta e | y_\\mathit{base}, y_\\mathit{repo}\\right) \\tag{2.20}\n\\end{align}\\]normalised savings workflow, numerical model trained baseline reporting period data. trained model predicts energy consumption period normalised conditions, savings estimated comparing predictions.Two posterior distributions produced \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)_\\mathit{base}\\) \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)_\\mathit{repo}\\), similar way model trained period. validation metrics model checked using posterior predictions training period.Two posterior distributions produced \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)_\\mathit{base}\\) \\(\\left(\\theta^{(1)},...,\\theta^{(S)}\\right)_\\mathit{repo}\\), similar way model trained period. validation metrics model checked using posterior predictions training period.model computes set \\(S\\) posterior predictions normalised period, sampling parameter posterior distribution:\n\\[\\begin{align}\n\\tilde{y}_{\\mathit{norm}|\\mathit{base}}^{(s)} \\sim p\\left(y_\\mathit{norm} | \\theta=\\theta_\\mathit{base}^{(s)}\\right) \\tag{2.21}\\\\\n\\tilde{y}_{\\mathit{norm}|\\mathit{repo}}^{(s)} \\sim p\\left(y_\\mathit{norm} | \\theta=\\theta_\\mathit{repo}^{(s)}\\right)\\tag{2.22}\n\\end{align}\\]model computes set \\(S\\) posterior predictions normalised period, sampling parameter posterior distribution:\n\\[\\begin{align}\n\\tilde{y}_{\\mathit{norm}|\\mathit{base}}^{(s)} \\sim p\\left(y_\\mathit{norm} | \\theta=\\theta_\\mathit{base}^{(s)}\\right) \\tag{2.21}\\\\\n\\tilde{y}_{\\mathit{norm}|\\mathit{repo}}^{(s)} \\sim p\\left(y_\\mathit{norm} | \\theta=\\theta_\\mathit{repo}^{(s)}\\right)\\tag{2.22}\n\\end{align}\\]can obtain \\(S\\) values savings \\(S\\) pairs predictions:\n\\[\\begin{equation}\n\\Delta e^{(s)} = \\sum_{=1}^n\\left(\\tilde{y}_{\\mathit{norm}|\\mathit{base}}^{(s)}() - \\tilde{y}_{\\mathit{norm}|\\mathit{repo}}^{(s)}()\\right) \\tag{2.23}\n\\end{equation}\\]can obtain \\(S\\) values savings \\(S\\) pairs predictions:\n\\[\\begin{equation}\n\\Delta e^{(s)} = \\sum_{=1}^n\\left(\\tilde{y}_{\\mathit{norm}|\\mathit{base}}^{(s)}() - \\tilde{y}_{\\mathit{norm}|\\mathit{repo}}^{(s)}()\\right) \\tag{2.23}\n\\end{equation}\\]","code":""},{"path":"back-bayes.html","id":"tools","chapter":"2 Bayesian data analysis","heading":"2.4.2 Software tools","text":"rest guide series tutorials reader may see methods practice. Unlike classical regression, modelling part requires stepping Excel spreadsheets using dedicated computing environment.use Stan platform statistical modelling. algorithms accessible interfaces scientific computing languages: Python, R, Julia, Matlab…majority Stan users seem favor R language, hence choice tutorials. alternative full Stan models, rstanarm R package “people open Bayesian inference using Bayesian software easier use frequentist software otherwise”Python users, PyMC Pyro popular Bayesian modelling alternatives. Julia users may use Turing. Stan models propose can still interfaced two languages.Additionally, specialised plotting libraries made exploratory analysis Bayesian models. recommend users give try:bayesplot R package Stan models;ArviZ package Python Julia.","code":""},{"path":"optClinreg.html","id":"optClinreg","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3 Tutorial 1: linear regression and introduction to Stan","text":"first tutorial serves introduction Stan platform, shows Bayesian analysis obtains uncertainty assessments classical methods, analytical solutions available.purpose, use short dataset ordinary linear regression model.","code":""},{"path":"optClinreg.html","id":"data","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.1 Data","text":"data monthly measurements whole-facility energy use (kWh), well heating degree-days cooling degree-days (°C.day).\nFigure 3.1: Electricity use vs. heating degree days; blue: pre-ECM; red: post-ECM\n","code":"\nlibrary(rstan)\nlibrary(tidyverse)\n\n# Baseline data: cooling and heating degree days, energy use\ndf.pre <- data.frame(cdd = c(0, 10, 15, 21, 21, 14, 0, 0, 0, 0, 0, 0),\n                     hdd = c(14, 0, 0, 0, 0, 0, 2, 20, 18, 32, 27, 20),\n                     use = c(35936, 22260, 20970, 25438, 28547, 24394,\n                             24224, 38767, 42205, 49649, 43540, 43734))\n# Reporting period data: cooling and heating degree days, energy use\ndf.post <- data.frame(cdd = c(0, 3, 13, 23, 19, 16, 0, 0, 0, 0, 0, 0),\n                      hdd = c(5, 0, 0, 0, 0, 0, 2, 19, 20, 24, 25, 14),\n                      use = c(25416, 17445, 13626, 19295, 17970, 15158,\n                              13293, 35297, 35665, 38562, 33383, 37244))\n\nggplot() +\n  geom_point(data = df.pre, aes(x=hdd, y=use), color=\"blue\") +\n  geom_point(data = df.post, aes(x=hdd, y=use), color=\"red\")"},{"path":"optClinreg.html","id":"model-specification-first-look-at-a-stan-model","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.2 Model specification: first look at a Stan model","text":"","code":""},{"path":"optClinreg.html","id":"ordinary-linear-regression","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.2.1 Ordinary linear regression","text":"quick look data, can assume linear relationship dependent variable (energy use) explanatory variables (hdd cdd).wrote longer lecture ordinary linear regression . don’t differentiate simple multiple regression, .e. models one several explanatory variable, since solved way.consider dependent variable \\(y\\), set \\(k\\) explanatory (independent) variables \\(x=(x_1,...,x_k)\\), assume series \\(n\\) values measured. therefore vector \\(\\mathbf{y}=\\left\\{y_i\\right\\}_{=1}^n\\) matrix \\(X = \\left\\{x_{i1},...x_{ik}\\right\\}_{=1}^n\\) dependent independent variable measurements.ordinary linear regression model states distribution \\(y_i\\) given predictors \\(\\mathbf{X}_i\\) normal mean linear function:\n\\[\\begin{align}\n    y_i & = \\alpha + \\beta_1 x_{i1} + ... + \\beta_k x_{ik} + \\varepsilon_i  \\tag{3.1} \\\\\n  \\varepsilon_i & \\sim \\mathrm{normal}(0, \\sigma) \\tag{3.2}\n\\end{align}\\]\nmatrix form:\n\\[\\begin{equation}\n    \\mathbf{y} = \\alpha + \\mathbf{X} \\cdot \\mathbf{\\beta} + \\mathbf{\\varepsilon}    \\tag{3.3}\n\\end{equation}\\]\nparameters \\((\\alpha, \\beta_1, ..., \\beta_k, \\sigma)\\) vector coefficients determined. Ordinary linear regression assumes normal linear model observation errors \\(\\varepsilon_i\\) independent equal variance \\(\\sigma^2\\) (hypothesis homoscedasticity).","code":""},{"path":"optClinreg.html","id":"linear-regression-with-stan","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.2.2 Linear regression with Stan","text":"Linear regression naturally first example given Stan documentation. following model extended bit purpose study.Stan model can either written separate file, included R script (language) follows:code made several blocks delimited braces. seven types blocks Stan model, used four . order important code, describe another order:model block center Stan code. declare model relates dependent variable \\(y\\) (energy use) explanatory variables \\(x\\) (heating cooling degree-days):line states expect \\(y\\) normally distributed around linear function \\(\\alpha + \\mathbf{X} \\cdot \\mathbf{\\beta}\\), standard deviation \\(\\sigma\\). identical Eq. (3.3).data block contains definition data passed model. variables declared block arguments model use: vector \\(\\mathbf{y}\\) matrix \\(\\mathbf{X}\\) “pre” “post” periods. number data items also requirement, since used variable Stan model.parameters block declares variables learned model training: intercept \\(\\alpha\\), slopes \\(\\beta\\) noise scale \\(\\sigma\\).generated quantities block optional influence model training. used evaluate function parameters \\(f(\\theta)\\) every sample, may directly obtain posterior distribution \\(p(f(\\theta)|y)\\) (see Eq. (2.11)). Two variables computed :\npredict_pre predict_post model’s prediction energy use pre post-ECM periods. use parameter models \\((\\alpha, \\beta, \\sigma)\\) learned pre-retrofit data, matrix dependent variables period.\nsavings total difference measured predicted post-retrofit energy use.\nincluding two variables generated quantities block.\npredict_pre predict_post model’s prediction energy use pre post-ECM periods. use parameter models \\((\\alpha, \\beta, \\sigma)\\) learned pre-retrofit data, matrix dependent variables period.savings total difference measured predicted post-retrofit energy use.\nincluding two variables generated quantities block.","code":"\nlinearregression <- \"\ndata {\n// Baseline data (pre)\n  int<lower=0> N;     // number of data items\n  int<lower=0> K;     // number of predictors\n  matrix[N, K] x;     // predictor matrix\n  vector[N] y;        // outcome vector\n// Reporting period data (post)\n  int<lower=0> N_post;  // number of data items\n  matrix[N, K] x_post;     // predictor matrix\n  vector[N] y_post;        // outcome vector\n}\nparameters {\n  real alpha;           // intercept\n  vector[K] beta;       // coefficients for predictors\n  real<lower=0> sigma;  // error scale\n }\nmodel {\n  y ~ normal(alpha + x * beta, sigma);  // likelihood\n}\ngenerated quantities {\n  vector[N] predict_pre;\n  vector[N_post] predict_post;\n  real savings = 0;\n  \n  for (n in 1:N) {\n    predict_pre[n] = normal_rng(x[n] * beta + alpha, sigma);\n  }\n  \n  for (n in 1:N_post) {\n    predict_post[n] = normal_rng(x_post[n] * beta + alpha, sigma);\n    savings += predict_post[n] - y_post[n];\n  }\n}\n\"model {\n  y ~ normal(alpha + x * beta, sigma);\n}"},{"path":"optClinreg.html","id":"model-fit-and-inference-diagnostics","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.3 Model fit and inference diagnostics","text":"","code":""},{"path":"optClinreg.html","id":"sampling-from-the-posterior","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.3.1 Sampling from the posterior","text":"next step map data contained df.pre df.post dataframes Stan model. defining list variables match items defined data block:first column \\(\\mathbf{X}\\) matrix cooling degree-days, second column heating degree-days.can now get fit following command. important arguments :model_code points Stan code. chose write R code separate file, instance called linearregression.stan, may replace line model_code = linearregression file = 'linearregression.stan' (pointing appropriate location file).data points list variables just defined.chains least 4.iter number iterations per chain.warmup number discarded iterations start every chain.\nDefault values chains = 4, warmup = 1000 iter = 2000, result chains*(iter-warmup)=4000 samples. appeared slightly insufficient case small dataset, raised iter.Model fitting takes longer first time stan() command run, model must first compiled. compilation however required per model, means running new data faster.","code":"\ndata_list <- list(N = nrow(df.pre),\n                  K = 2,\n                  x = df.pre %>% select(cdd, hdd),\n                  y = df.pre$use,\n                  N_post = nrow(df.post),\n                  x_post = df.post %>% select(cdd, hdd),\n                  y_post = df.post$use)\nfit <- stan(\n  model_code = linearregression,  # Stan program\n  data = data_list,        # named list of data\n  chains = 4,               # number of Markov chains\n  warmup = 1000,            # number of warmup iterations per chain\n  iter = 3000,              # total number of iterations per chain\n  cores = 2,                # number of cores (could use one per chain)\n  refresh = 0,              # progress not shown\n)"},{"path":"optClinreg.html","id":"results","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.3.2 Results","text":"fit object returned stan associated methods print, plot pairs, letting us first look results.print method shows posterior metrics parameters generated quantities: mean, standard deviation, quantiles, effective sample size, R-hat.traceplot shows traces selected parameters variables. fitting converged, traces coincide approximate posterior distributions.\nFigure 3.2: Traces regression coefficients\npairs shows pairwise relationships parameters. Strong interactions parameters indication model re-parameterised.\nFigure 3.3: Pairplot regression coefficients\n","code":"\nprint(fit, pars=c(\"alpha\", \"beta\", \"sigma\", \"savings\"), probs=c(.025,.5,.975))## Inference for Stan model: anon_model.\n## 4 chains, each with iter=3000; warmup=1000; thin=1; \n## post-warmup draws per chain=2000, total post-warmup draws=8000.\n## \n##             mean se_mean       sd     2.5%      50%     97.5% n_eff Rhat\n## alpha   22869.14   56.85  2566.67 17778.70 22854.90  28107.04  2038    1\n## beta[1]   115.60    3.67   173.61  -226.77   117.47    465.08  2239    1\n## beta[2]   872.38    2.65   124.44   617.87   873.58   1124.87  2201    1\n## sigma    3132.76   20.49   914.82  1905.86  2939.05   5517.54  1993    1\n## savings 75696.75  203.12 16375.91 43296.92 75768.33 107740.79  6500    1\n## \n## Samples were drawn using NUTS(diag_e) at Tue Jun 20 14:18:48 2023.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\ntraceplot(fit, pars=c(\"alpha\", \"beta\", \"sigma\", \"savings\"))\npairs(fit, pars=c(\"alpha\", \"beta\", \"sigma\", \"savings\"))## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter"},{"path":"optClinreg.html","id":"inferencediagnostics","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.3.3 Inference diagnostics","text":"Running stan() command may return variety warnings help users diagnose resolve underlying modelling problems.order draw reliable inferences results, need least green lights:High enough effective sample size (ESS) parameters (seen table shown print);R-hat lower 1.01, ensure chains converged;remaining warnings BFMI (Bayesian fraction missing information), divergent transitions maximum treedepth.criteria may seem obscure new users Bayesian computation, ignored. guide suggests ways solve problems. part larger workflow model building, testing critique/evaluation.first thing try traces converged increase warmup iterations. may enough get better ESS R-hatThere possible “hidden” adjustments MCMC algorithm solve warnings (see example)problems remain, might sign model inadequacy. solution reduce model use stronger priors, data may sufficient inform parameters.Diagnostics may facilitated use specialised plotting libraries made exploratory analysis Bayesian models:bayesplot R packageThe ArviZ package Python Julia methods dedicated inference diagnostics","code":"fit <- stan(...\n            control = list(adapt_delta = 0.99, stepsize = 0.01, max_treedepth = 15)\n)"},{"path":"optClinreg.html","id":"model-checking-and-validation","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.4 Model checking and validation","text":"","code":""},{"path":"optClinreg.html","id":"measures-of-model-adequacy","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.4.1 Measures of model adequacy","text":"MCMC convergence necessary, guarantee model best choice case! Assessing adequacy fitted model just necessary Bayesian framework classical frequentist methods.extract function returns model parameters generated quantities named list.instance la$alpha la$savings hold value parameter \\(\\alpha\\) estimated savings many samples (example , \\(N_s=8000\\) samples). Similarly, la$prediction \\(N_s\\times 12\\) matrix \\(N_s\\) samples predicted energy use.way summarise posterior predictions quantiles:\nFigure 3.4: Comparison model prediction measurements pre period\ncan calculate usual metrics mean posterior prediction: coefficient determination \\(R^2\\), CV(RMSE), F-statistic…Prediction residuals low autocorrelation. can checked Durbin-Watson statistic, autocorrelation plot:\nFigure 3.5: Autocorrelation function linear model residuals\nwon’t elaborate much plot focus next tutorial. short, simple linear model low autocorrelation residuals: criterion satisfied. However, \\(R^2\\) index quite low: significant part data’s variance unexplained.","code":"\nla <- rstan::extract(fit, permuted = TRUE)\nsummary(la$savings)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  -19933   65558   75768   75697   85640  174954\n# median, lower and upper bounds of the 95% prediction intervals\npredict.pre <- apply(la$predict_pre, 2, quantile, probs=c(0.025, 0.5, 0.975))\n# mean prediction\npredict.mean <- colMeans(la$predict_pre)\n\n# Plot of the median and 95% prediction intervals\nggplot(mapping = aes(x = array(1:nrow(df.pre)))) +\n  geom_point(mapping = aes(y = df.pre$use)) +\n  geom_line(mapping = aes(y = predict.pre[2,]), color='red') +\n  geom_ribbon(mapping = aes(ymin=predict.pre[1,], ymax=predict.pre[3,]), fill='red', alpha=0.1) +\n  labs(x = \"Month\", y=\"Energy use (kWh)\")\nresiduals <- predict.mean - df.pre$use        # residuals\nssres <- sum(residuals^2)                     # sum of squared residuals\nsstot <- sum((df.pre$use-mean(df.pre$use))^2) # total sum of squares\n\nR2 <- 1 - ssres / sstot   # coefficient of determination\nCVRMSE <- sqrt(ssres / nrow(df.pre)) / mean(df.pre$use)\n\nprint(paste(\"R2 =\", R2))\nprint(paste(\"CV(RMSE) =\", CVRMSE))## [1] \"R2 = 0.942258713375518\"\n## [1] \"CV(RMSE) = 0.0696138062666448\"\nacf(residuals)"},{"path":"optClinreg.html","id":"checking-model-parameters","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.4.2 Checking model parameters","text":"Individual parameter adequacy can checked \\(t\\)-statistic \\(p\\)-value.can see one \\(p\\)-value 0.05: beta[1] regression coefficient cooling degree-days.pairwise correlation parameters already visible pairplot shown earlier. high correlation , can confirm quantitatively:","code":"\n# Trace of all parameters and generated quantities\ntraces <- as.data.frame(fit)\n# Only the parameters\ntraces.p <- traces %>% select('alpha', 'beta[1]', 'beta[2]', 'sigma')\n\n# The t-statistic is the ratio of mean to standard deviation of parameters\nt_stat <- colMeans(traces.p) / sapply(traces.p, sd)\n# The p-value is easy to calculate from the t statistics\nptest <- 2*pt(-abs(t_stat), df=nrow(df.pre))\n\nprint(ptest)##        alpha      beta[1]      beta[2]        sigma \n## 1.227476e-06 5.181084e-01 1.414004e-05 5.036975e-03\ncor(traces.p)##                alpha      beta[1]     beta[2]        sigma\n## alpha    1.000000000 -0.861666528 -0.87471809  0.004493572\n## beta[1] -0.861666528  1.000000000  0.76152890  0.009350584\n## beta[2] -0.874718086  0.761528904  1.00000000 -0.015556055\n## sigma    0.004493572  0.009350584 -0.01555605  1.000000000"},{"path":"optClinreg.html","id":"prediction-of-savings","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.5 Prediction of savings","text":"partially reassured adequacy model: \\(R^2\\) high, one parameter may statistically significant, parameters quite correlated. autocorrelation criterion however satisfactory: means may obtain unbiased estimates energy savings, probably high uncertainty.Let’s fit regular deterministic linear model, order compare results Bayesian method:Yes, simple.coefficients Bayesian output. Without model checking, can expect conclusions.Let’s now compare energy use predictions post-retrofit period, Bayesian method (red) classical method (blue):\nFigure 3.6: Model predictions measurements post period\nPredictions methods look almost exactly . Finally, let’s compare basis energy savings predictions. following block generates table containing mean, lower upper bounds 95% confidence interval, predicted energy savings.mean savings estimate method (less 1% difference), discrepancy lower upper bounds 95% interval. don’t believe real reason gap since specification models identical. probably caused finite number samples properly approximate tails posterior distribution.","code":"\nfit2 <- lm(use ~ cdd + hdd, df.pre)\nsummary(fit2)## \n## Call:\n## lm(formula = use ~ cdd + hdd, data = df.pre)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3608.1 -1596.3  -225.6  1464.2  3636.7 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  22860.4     2136.0  10.702 2.03e-06 ***\n## cdd            114.5      142.6   0.803    0.443    \n## hdd            872.7      104.2   8.374 1.53e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2681 on 9 degrees of freedom\n## Multiple R-squared:  0.9421, Adjusted R-squared:  0.9292 \n## F-statistic: 73.24 on 2 and 9 DF,  p-value: 2.702e-06\n# Model predictions during the \"post\" period\npredict.post <- apply(la$predict_post, 2, quantile, probs=c(0.025, 0.5, 0.975))\n# Predictions from an ordinary linear regression model\npredict.2 <- predict(fit2, newdata = df.post, interval = \"prediction\", level=0.95)\n\nxplot <- array(1:nrow(df.post))\nggplot(mapping = aes(x = xplot)) +\n  geom_point(mapping = aes(y = df.post$use)) +\n  geom_line(mapping = aes(y = predict.post[2,]), color='red') +\n  geom_line(mapping = aes(y = predict.2[,1]), color='blue') +\n  geom_ribbon(mapping = aes(ymin=predict.post[1,], ymax=predict.post[3,]), fill='red', alpha=0.1) +\n  geom_ribbon(mapping = aes(ymin=predict.2[,2], ymax=predict.2[,3]), fill='blue', alpha=0.1)\nmethod <- c(\"bayesian\", \"classical\")\n# Mean savings\nmean.savings <- c(mean(la$savings),\n                  sum(predict.2[,1] - df.post$use))\n# Lower and upper bounds of the 95% confidence interval of savings\nlower.bound <- c(sum(predict.post[1,] - df.post$use),\n                 sum(predict.2[,2] - df.post$use))\nupper.bound <- c(sum(predict.post[3,] - df.post$use),\n                 sum(predict.2[,3] - df.post$use)) \nsvgs <- data.frame(method, mean.savings, lower.bound, upper.bound)\n\nprint(svgs)##      method mean.savings lower.bound upper.bound\n## 1  bayesian     75696.75  -12679.896    164579.1\n## 2 classical     75564.54   -6385.537    157514.6"},{"path":"optClinreg.html","id":"conclusion","chapter":"3 Tutorial 1: linear regression and introduction to Stan","heading":"3.6 Conclusion","text":"tutorial, showed perform Bayesian linear regression Stan, typical M&V workflow. estimate post-retrofit energy savings, adjusted heating cooling degree-days.showed obtain results (parameter estimates, model validation metrics, energy use predictions, savings uncertainty) Bayesian approach deterministic ordinary linear regression method. Bayesian method seems much complicated classical method, ’ll show next tutorials workflow remain regardless model complexity, classical approach may longer simple solutions estimating savings uncertainty.","code":""},{"path":"optCchangepoint.html","id":"optCchangepoint","chapter":"4 Tutorial 2: increasing model complexity","heading":"4 Tutorial 2: increasing model complexity","text":"first tutorial reassured us ability Bayesian method obtain results (energy use predictions, savings uncertainty, model checking validation metrics) analytically.second tutorial now illustrates two advantages:ability automatically estimate uncertainty regardless model structure;ability include prior knowledge model parameters.","code":""},{"path":"optCchangepoint.html","id":"data-1","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.1 Data","text":"","code":""},{"path":"optCchangepoint.html","id":"data-overview","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.1.1 Data overview","text":"data used example hourly electricity consumption outdoor air temperature data commercial building Richmond, USA. Three file available: building6pre.csv, building6during.csv building6post.csv, respectively energy conservation measure applied.\nFigure 4.1: Pre-ECM data (first 6 months)\ndata hourly time step size. Every hour, outdoor air temperature energy use available.electricity use higher summer winter mid-season. suggests consumption data includes heating cooling appliances.Week-ends clearly visible lower consumption working days week.","code":"\nlibrary(rstan)\nlibrary(tidyverse)\nlibrary(lubridate)\n\ndf.pre  <- read_csv(\"data/building6pre.csv\")  %>% mutate(Date = mdy_hm(Date))\ndf.dur  <- read_csv(\"data/building6during.csv\")  %>% mutate(Date = mdy_hm(Date))\ndf.post <- read_csv(\"data/building6post.csv\") %>% mutate(Date = mdy_hm(Date))\n\nggplot() +\n  geom_line(data = df.pre %>% filter(month(Date)<7),\n            mapping = aes(x=Date, y=`Building 6 kW`))"},{"path":"optCchangepoint.html","id":"subset-selection","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.1.2 Subset selection","text":"Averaging data daily time steps allow overlook dependence consecutive measurements. turn, allows using model much simpler time series models, capable low frequency predictions.following block creates new datasets original ones:Measurements daily averagedA categorical variable added indicate week ends., plot daily energy use \\(E\\) (kWh) versus outdoor temperature \\(T\\) (°C) values week.end categorical variable “pre” dataset.\nFigure 4.2: Daily electricity use vs outdoor temperature\nseems fitting train separate models working days week ends, energy use clearly different two sets. tutorial, consider working days, aren’t many available data points week ends, possible .Finally filter weekends compare three datasets terms energy use versus outdoor temperature:\nFigure 4.3: Daily electricity use vs outdoor temperature, selected data three periods\n","code":"\ndaily.average <- function(df) {\n  df %>% \n    mutate(day = as_date(Date)) %>%\n    group_by(day) %>% \n    summarise(T = (mean(OAT)-32)/1.8,\n              E = sum(`Building 6 kW`),\n              .groups = 'drop') %>% \n    mutate(wday = wday(day),\n           week.end = wday==1 | wday==7)\n}\n\ndf.pre.day  <- daily.average(df.pre)\ndf.dur.day  <- daily.average(df.dur)\ndf.post.day <- daily.average(df.post)\n\nggplot(data = df.pre.day) +\n  geom_point(mapping = aes(x=T, y=E, color=week.end))\ndf.pre.day  <- df.pre.day  %>% filter(!week.end) %>% mutate(period = 'pre')\ndf.dur.day  <- df.dur.day  %>% filter(!week.end) %>% mutate(period = 'during')\ndf.post.day <- df.post.day %>% filter(!week.end) %>% mutate(period = 'post')\n\ndf.all <- bind_rows(df.pre.day, df.dur.day, df.post.day)\n\nggplot(data = df.all, aes(x=T, y=E, color=period)) + geom_point()"},{"path":"optCchangepoint.html","id":"modelling-and-training","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.2 Modelling and training","text":"","code":""},{"path":"optCchangepoint.html","id":"model-specification","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.2.1 Model specification","text":"looking data, can suggest using change-point model include effects heating cooling separately. expected daily energy use \\(y\\) (kWh per day) function outdoor temperature \\(x\\) number parameters:\\[\\begin{align}\ny_n & = \\alpha + \\beta_{h}(\\tau_{h}-x_n)^+ + \\beta_{c}(x_n-\\tau_{c})^+ + \\varepsilon_n \\tag{4.1} \\\\\n\\varepsilon_n & \\sim \\mathrm{normal}\\left(0, \\sigma\\right) \\tag{4.2}\n\\end{align}\\]\\(h\\) \\(c\\) subscripts indicate heating cooling modes. \\(+\\) superscript indicates term applied zero. equation means expect energy use \\(y\\) normal distribution centered around change-point model, constant standard deviation \\(\\sigma\\).model 6 possible parameters: constant term \\(\\alpha\\), two slopes \\(\\beta\\), two change points \\(\\tau\\) error scale \\(\\sigma\\). ordinary linear regression models: analytical way formulate prediction uncertainty accounting uncertainty change point estimates.","code":""},{"path":"optCchangepoint.html","id":"model-specification-with-stan","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.2.2 Model specification with Stan","text":"Stan code full model written separate file changepoint.stan. show parts . See Tutorial 1 quick introduction components Stan model.names data variables parameters declared data parameter blocks don’t show . names clear specification model. model block:main difference first tutorial added prior distributions parameters. help regularizing inverse problem may non-unique set solutions. adding priors, “help” traces converge towards physically consistent values chose looking data.also generated quantities block:block handles calculation posterior variables want watch: energy use predictions model “pre” “post” periods, energy savings.Note predictions calculated drawing Normal distribution \\(\\sigma\\) error sample. Therefore, obtain full description prediction intervals.","code":"model {\n  // Assigning prior distributions on some parameters\n  alpha ~ normal(800, 100);\n  tau_h ~ normal(8, 5);\n  tau_c ~ normal(18, 5);\n  beta_h ~ normal(40, 15);\n  beta_c ~ normal(40, 15);\n  // Observational model\n  for (n in 1:N_pre) {\n    y_pre[n] ~ normal(alpha + beta_h * fmax(tau_h-x_pre[n], 0)\n                            + beta_c * fmax(x_pre[n]-tau_c, 0), sigma);\n  }\n}generated quantities {\n  // This block is for posterior predictions. It is not part of model training\n  vector[N_pre] y_pre_pred;\n  vector[N_post] y_post_pred;\n  real savings = 0;\n  \n  for (n in 1:N_pre) {\n    y_pre_pred[n] = normal_rng(alpha + beta_h * fmax(tau_h-x_pre[n], 0)\n                                     + beta_c * fmax(x_pre[n]-tau_c, 0), sigma);\n  }\n  \n  for (n in 1:N_post) {\n    y_post_pred[n] = normal_rng(alpha + beta_h * fmax(tau_h-x_post[n], 0)\n                                      + beta_c * fmax(x_post[n]-tau_c, 0), sigma);\n    savings += y_post_pred[n] - y_post[n];\n  }\n}"},{"path":"optCchangepoint.html","id":"model-fitting","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.2.3 Model fitting","text":"next step create list called model_data, maps data appropriate variable Stan model.stan() command fits model, given changepoint.stan file, using data.first tutorial, fitting may result number warnings, telling us problems may occurred: divergent transitions, large R-hat values, low Effective Sample Size… Obtaining fit without warnings takes practice essential unbiased interpretation inferred variables predictions.lot problems can solved appropriate choice priors.","code":"\nmodel_data <- list(\n  N_pre = nrow(df.pre.day),\n  x_pre = df.pre.day$T,\n  y_pre = df.pre.day$E,\n  N_post = nrow(df.post.day),\n  x_post = df.post.day$T,\n  y_post = df.post.day$E\n)\n\n# Fitting the model\nfit <- stan(\n  file = 'models/changepoint.stan',  # Stan program\n  data = model_data,        # named list of data\n  chains = 4,               # number of Markov chains\n  warmup = 1000,            # number of warmup iterations per chain\n  iter = 2000,              # total number of iterations per chain\n  cores = 2,                # number of cores (could use one per chain)\n  refresh = 0,              # progress not shown\n)"},{"path":"optCchangepoint.html","id":"results-1","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.3 Results","text":"","code":""},{"path":"optCchangepoint.html","id":"first-look-at-results","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.3.1 First look at results","text":"first look can results comes print, plot pairs methods associated fit object:Inference diagnostics fine: parameters, n_eff thousands Rhat 1.model parameters statistically significant: 95% confidence interval doesn’t include zero.traces converged range.pairplot suggests strong correlation parameters, nothing alarming.","code":"\nprint(fit, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"savings\"))## Inference for Stan model: changepoint.\n## 4 chains, each with iter=2000; warmup=1000; thin=1; \n## post-warmup draws per chain=1000, total post-warmup draws=4000.\n## \n##             mean se_mean      sd     2.5%      25%      50%      75%    97.5%\n## alpha     829.64    0.24   11.88   804.68   822.03   829.99   837.98   851.42\n## beta_h     33.37    0.06    2.68    28.19    31.55    33.38    35.15    38.67\n## tau_h       6.51    0.02    0.75     5.23     5.98     6.45     6.97     8.15\n## beta_c     29.26    0.07    3.24    23.16    27.02    29.11    31.42    35.84\n## tau_c      15.78    0.02    0.98    13.70    15.16    15.84    16.47    17.50\n## sigma      96.70    0.08    4.34    88.56    93.79    96.55    99.58   105.64\n## savings 49922.98   35.51 2253.21 45425.69 48464.88 49899.17 51406.99 54365.56\n##         n_eff Rhat\n## alpha    2377    1\n## beta_h   2256    1\n## tau_h    1790    1\n## beta_c   2451    1\n## tau_c    2068    1\n## sigma    3256    1\n## savings  4027    1\n## \n## Samples were drawn using NUTS(diag_e) at Thu Mar 30 15:15:55 2023.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\ntraceplot(fit, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"lp__\"))\npairs(fit, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"savings\"))## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter"},{"path":"optCchangepoint.html","id":"model-checking","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.3.2 Model checking","text":"model checking metrics usual: coefficient determination \\(R^2\\), CV(RMSE), F-statistic… calculate mean prediction rather full posterior distribution.check parameter adequacy \\(p\\)-test:","code":"\nla <- rstan::extract(fit, permuted = TRUE)\npredict.mean <- colMeans(la$y_pre_pred)\n\nresiduals <- predict.mean - df.pre.day$E      # residuals\nssres <- sum(residuals^2)                     # sum of squared residuals\nsstot <- sum((df.pre.day$E-mean(df.pre.day$E))^2) # total sum of squares\n\nR2 <- 1 - ssres / sstot   # coefficient of determination\nCVRMSE <- sqrt(ssres / nrow(df.pre.day)) / mean(df.pre.day$E)\n\nprint(paste(\"R2 =\", R2))\nprint(paste(\"CV(RMSE) =\", CVRMSE))## [1] \"R2 = 0.658934362997056\"\n## [1] \"CV(RMSE) = 0.0983950183032571\"\n# Trace of all parameters and generated quantities\ntraces <- as.data.frame(fit)\n# Only the parameters\ntraces.p <- traces %>% select('alpha', 'beta_h', 'beta_c', 'tau_h', 'tau_c', 'sigma')\n\n# The t-statistic is the ratio of mean to standard deviation of parameters\nt_stat <- colMeans(traces.p) / sapply(traces.p, sd)\n# The p-value is easy to calculate from the t statistics\nptest <- 2*pt(-abs(t_stat), df=nrow(df.pre.day))\n\nprint(ptest)##         alpha        beta_h        beta_c         tau_h         tau_c \n## 1.659427e-170  2.739440e-28  4.183726e-17  5.011267e-16  3.331417e-41 \n##         sigma \n##  3.747296e-62"},{"path":"optCchangepoint.html","id":"tuto2predictions","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.3.3 Predictions and savings","text":"Stan model already calculates expected output \\(y\\) reporting period, sample \\(\\theta_i\\) posterior distribution. can therefore display probability distribution data points reporting period, compare measured data period.following graph compares energy use measured reporting period (points) probability distributions energy use predicted model period.\nFigure 4.4: Model predictions measurements post period\ncolored bands show 95% prediction interval. points measurements “post” period.savings, .e. difference measured energy use reporting period prediction model, included Stan model well. Similarly prediction, savings therefore available probability distribution: full description confidence interval may wish .can also choose display quantile posterior distribution savings. line displays mean expected savings bounds 80% 95% intervals:","code":"\n# This method is more convenient to extract prediction quantiles and mean\npredict.quan <- apply(la$y_post_pred, 2, quantile, probs=c(0.025, 0.5, 0.975))\n\n# Adding prediction quantiles to the baseline dataframe\ndf.post.day <- df.post.day %>% mutate(pred_low = predict.quan[1, ],\n                                    pred_med = predict.quan[2, ],\n                                    pred_up = predict.quan[3, ])\n\n# Plot\nggplot(data = df.post.day) +\n  geom_point(mapping = aes(x=T, y=E)) +\n  geom_line(mapping = aes(x=T, y=pred_med), color='red') +\n  geom_ribbon(mapping = aes(x=T, ymin=pred_low, ymax=pred_up), fill='red', alpha=0.1)\nquantile(la$savings, probs=c(0.025, 0.1, 0.5, 0.9, 0.975))\n# plot(fit, pars = c(\"savings\") )##     2.5%      10%      50%      90%    97.5% \n## 45425.69 47046.76 49899.17 52841.86 54365.56"},{"path":"optCchangepoint.html","id":"tuto2residuals","chapter":"4 Tutorial 2: increasing model complexity","heading":"4.4 Residuals","text":"one thing didn’t check.important validation step check autocorrelation residuals fitted model, baseline data used fitting. Autocorrelation often sign insufficient model complexity, form model error term appropriately chosen. case strong remaining autocorrelation, inferences drawn caution.autocorrelation function (ACF) easiest way display autocorrelation variable residuals:\nFigure 4.5: Autocorrelation function prediction residuals\nEvery vertical line graph shows correlation coefficient values series (residuals) values certain lag.Lag=0, ACF 1. normal: series fully correlated .much possible, want ACF values dotted line, threshold value depends length data.Lag=1, ACF close 0.7. average correlation coefficient residuals previous value. consequence, next lags high ACF values well.increased ACF every 5 lags. Reminder: removed weekends, therefore dataset 5 rows per week. data weekly pattern model doesn’t capture.can zoom lag-1 autocorrelation plotting residuals versus previous value:\nFigure 4.6: Correlation consecutive residuals\nautocorrelation graph suggests model doesn’t predict variability data properly. therefore cautious interpreting inferences. includes uncertainty savings estimates.order trust inferences, two options:Improve model better describes building’s electricity use dependency weather occupancy. means model parameters, dataset may longer bring enough information identify .Modify model account additional uncertainty due autocorrelation. means “fix” model, let aknowledge missing something: inferences “cautious” (uncertain reliable).next tutorial, show second option.","code":"\nacf(residuals)\nggplot() +\n  geom_point(mapping = aes(x=residuals, y=lag(residuals, n=1, default=0)))"},{"path":"optCautocorr.html","id":"optCautocorr","chapter":"5 Tutorial 3: correlated residuals","heading":"5 Tutorial 3: correlated residuals","text":"tutorial 2, fitted change-point model, function outdoor air temperature, daily energy use data commercial building. gave us estimate energy savings following energy conservation measure, uncertainty. However saw autocorrelation model’s prediction residuals high trust inference.fitted model autocorrelated residuals, two options :possible, improve model better description building occupancy;possible improve model , data insufficient learn additional parameters, autocorrelation remains, can somehow “include ” model.second option means “fix” model, let aknowledge missing something. Making reliable predictions come cost increased uncertainty.","code":""},{"path":"optCautocorr.html","id":"moving-average-models","chapter":"5 Tutorial 3: correlated residuals","heading":"5.1 Moving average models","text":"far, models used tutorial 1 2 looked like :\\[\\begin{equation}\ny_t = f(x_t) + \\varepsilon_t \\tag{5.1}\n\\end{equation}\\]\\(y_t\\) observed dependent data (energy use) \\(f\\) can function explanatory variables \\(x_t\\) (outdoor temperature, occupancy, solar irradiance, etc.): linear, change-point, .However, found model fitting residuals correlated, Eq. (5.1) longer holds. Instead, previous tutorial found significant correlation consecutive errors \\(y_t - f(x_t)\\) model:\\[\\begin{equation}\ny_t - f(x_t) = \\theta_1 \\varepsilon_{t-1} + \\mathrm{normal}(0,\\sigma^2) \\tag{5.2}\n\\end{equation}\\]\\(\\theta_1\\) lag-1 autocorrelation Fig. 4.5 slope trend Fig. 4.6.observational model therefore:\\[\\begin{equation}\ny_t = f(x_t) + \\theta_1 \\varepsilon_{t-1} + \\varepsilon_t \\tag{5.3}\n\\end{equation}\\]last term equation errors new model, hope now independent longer autocorrelated: \\(\\varepsilon_t\\sim N(0,\\sigma^2)\\).general form equation, can even assume residuals correlated previous values higher lag \\(Q\\):\\[\\begin{equation}\ny_t = f(x_t) + \\theta_1 \\varepsilon_{t-1} + \\dots + \\theta_Q \\varepsilon_{t-Q} + \\varepsilon_t \\tag{5.4}\n\\end{equation}\\]formulation Moving Average (MA) model order \\(Q\\), \\(\\mathrm{MA}(Q)\\). uses previous errors predictors future outcomes. Compared original model \\(f(x_t)\\), model additional parameters \\(\\left(\\theta_1,...,\\theta_Q\\right)\\). Stan documentation page MA models, used starting point tutorial.","code":""},{"path":"optCautocorr.html","id":"data-2","chapter":"5 Tutorial 3: correlated residuals","heading":"5.2 Data","text":"first block just code beginning tutorial 2, rewritten .","code":"\nlibrary(rstan)\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Reading data and identifying the dates\ndf.pre  <- read_csv(\"data/building6pre.csv\")  %>% mutate(Date = mdy_hm(Date))\ndf.dur  <- read_csv(\"data/building6during.csv\")  %>% mutate(Date = mdy_hm(Date))\ndf.post <- read_csv(\"data/building6post.csv\") %>% mutate(Date = mdy_hm(Date))\n\n# Quick preprocessing and daily averaging\ndaily.average <- function(df) {\n  df %>% \n    mutate(day = as_date(Date)) %>%\n    group_by(day) %>% \n    summarise(T = (mean(OAT)-32)/1.8,\n              E = sum(`Building 6 kW`),\n              .groups = 'drop') %>% \n    mutate(wday = wday(day),\n           week.end = wday==1 | wday==7)\n}\n\n# Filtering out the week ends\ndf.pre.day  <- daily.average(df.pre) %>% filter(!week.end) %>% mutate(period = 'pre')\ndf.dur.day  <- daily.average(df.dur) %>% filter(!week.end) %>% mutate(period = 'during')\ndf.post.day <- daily.average(df.post) %>% filter(!week.end) %>% mutate(period = 'post')"},{"path":"optCautocorr.html","id":"modelling-and-training-1","chapter":"5 Tutorial 3: correlated residuals","heading":"5.3 Modelling and training","text":"","code":""},{"path":"optCautocorr.html","id":"model-specification-1","chapter":"5 Tutorial 3: correlated residuals","heading":"5.3.1 Model specification","text":"use change-point model tutorial 2, modified include regression term previous error \\(\\varepsilon_{n-1}\\). makes first order moving average model, \\(\\mathrm{MA}(1)\\):\\[\\begin{align}\ny_n & = \\alpha + \\beta_{h}(\\tau_{h}-x_n)^+ + \\beta_{c}(x_n-\\tau_{c})^+ + \\theta_1 \\varepsilon_{n-1} + \\varepsilon_n \\tag{5.5} \\\\\n\\varepsilon_n & \\sim \\mathrm{normal}\\left(0, \\sigma\\right) \\tag{5.6}\n\\end{align}\\]Stan code model separate file changepoint_ma1.stan, complicated original.Firstly, new block called transformed parameters, parameters model, calculates main terms Eq. (5.5) model written concisely.f_pre f_post values change-point function , respectively pre post periods.epsilon residuals according Eq. (5.5), calculated one another., model reproduces Eq. (5.5). formulation quite tidy, since defined term previous block.block starts definition priors, omitted although belong model. Priors important Bayesian workflow, often first way regularise model convergence difficult.Finally, generated quantities block used generate predictions energy use savings iteration.predictions energy use baseline (pre) period \\(\\tilde{y}_\\mathit{pre}\\) account previous residuals. However, keen eye may noticed difference predictions post period \\(\\tilde{y}_\\mathit{post}\\). Indeed, know value residuals fitting period, since difference model predictions consumption hypothetical building identical pre-ECM building post-ECM conditions.Therefore, muti-step prediction intervals ARIMA models (MA models subclass ) must account increased uncertainty \\(\\hat{\\sigma}_h\\) formulated MA regression coefficients \\(\\theta_i\\):\\[\\begin{align}\n\\tilde{y}_\\mathit{post} & \\sim \\mathrm{normal}\\left(f(x_\\mathit{post}), \\sigma_h^2 \\right) \\tag{5.7} \\\\\n\\hat{\\sigma}_h & = \\hat{\\sigma}^2 \\left[1+\\sum_{=1}^{h-1}\\hat{\\theta}_i^2\\right] \\tag{5.8}\n\\end{align}\\]one \\(\\theta_1\\) coefficient \\(\\mathrm{MA}(1)\\) model, Eq. (5.8) applies \\(\\mathrm{MA}(Q)\\) model may want include regression coefficients several past errors.still following, congratulations! concludes theoretical part tutorials.","code":"transformed parameters {\n  vector[N_pre] f_pre;\n  vector[N_pre] epsilon;\n  vector[N_post] f_post;\n  for (n in 1:N_pre) {\n    f_pre[n] = alpha + beta_h * fmax(tau_h-t_pre[n], 0) + beta_c * fmax(t_pre[n]-tau_c, 0);\n  }\n  epsilon[1] = y_pre[1] - f_pre[1];\n  for (n in 2:N_pre) {\n    epsilon[n] = y_pre[n] - f_pre[n] - theta*epsilon[n-1];\n  }\n  for (n in 1:N_post) {\n    f_post[n] = alpha + beta_h * fmax(tau_h-t_post[n], 0) + beta_c * fmax(t_post[n]-tau_c, 0);\n  }\n}model {\n  ...\n  for (n in 2:N_pre) {\n    y_pre[n] ~ normal(f_pre[n] + theta*epsilon[n-1], sigma);\n  }\n}generated quantities {\n  ...\n  \n  y_pre_pred[1] = normal_rng(f_pre[1], sigma);\n  for (n in 2:N_pre) {\n    y_pre_pred[n] = normal_rng(f_pre[n] + theta*epsilon[n-1], sigma);\n  }\n  \n  // Forecasts with increased uncertainty due to the autocorrelation\n  y_post_pred[1] = normal_rng(f_post[1], sigma);\n  for (n in 2:N_post) {\n    y_post_pred[n] = normal_rng(f_post[n], sigma * sqrt(1+theta^2));\n    savings += y_post_pred[n] - y_post[n];\n  }\n}"},{"path":"optCautocorr.html","id":"model-fitting-1","chapter":"5 Tutorial 3: correlated residuals","heading":"5.3.2 Model fitting","text":"next step tutorial 2: defining list maps data Stan model, calling stan() command fit model.notice convergence may difficult due added \\(\\theta\\) parameter: model knows something “uncertain” happening local optima may disturb traces. order help convergence, narrow prior distributions, increase warmup iteration numbers copiously.","code":"\nmodel_data <- list(\n  N_pre = nrow(df.pre.day),\n  x_pre = df.pre.day$T,\n  y_pre = df.pre.day$E,\n  N_post = nrow(df.post.day),\n  x_post = df.post.day$T,\n  y_post = df.post.day$E\n)\n\n# Fitting the model\nfit <- stan(\n  file = 'models/changepoint_ma1.stan',  # Stan program\n  data = model_data,        # named list of data\n  chains = 4,               # number of Markov chains\n  warmup = 3000,            # number of warmup iterations per chain\n  iter = 4000,              # total number of iterations per chain\n  cores = 2,                # number of cores (could use one per chain)\n  refresh = 0,              # progress not shown\n  seed = 123\n)"},{"path":"optCautocorr.html","id":"results-from-the-ma1-model","chapter":"5 Tutorial 3: correlated residuals","heading":"5.4 Results from the MA(1) model","text":"","code":""},{"path":"optCautocorr.html","id":"first-look-at-results-1","chapter":"5 Tutorial 3: correlated residuals","heading":"5.4.1 First look at results","text":"first look can results comes print, plot pairs methods associated fit object:Remember need validate inference diagnostics criteria! traces must match, n_eff thousands Rhat exactly 1 parameters.","code":"\nprint(fit, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"theta\", \"savings\"))## Inference for Stan model: anon_model.\n## 4 chains, each with iter=4000; warmup=3000; thin=1; \n## post-warmup draws per chain=1000, total post-warmup draws=4000.\n## \n##             mean se_mean      sd     2.5%      25%      50%      75%    97.5%\n## alpha     834.60    0.23   13.17   808.95   825.69   834.86   843.74   859.81\n## beta_h     32.91    0.05    2.71    27.66    31.06    32.92    34.70    38.22\n## tau_h       6.32    0.02    0.77     5.09     5.71     6.22     6.89     7.89\n## beta_c     27.73    0.06    2.82    22.60    25.70    27.62    29.66    33.59\n## tau_c      15.61    0.02    1.02    13.74    14.84    15.57    16.41    17.45\n## sigma      78.07    0.05    3.24    72.07    75.82    77.97    80.21    84.61\n## theta       0.57    0.00    0.04     0.49     0.55     0.58     0.60     0.65\n## savings 50211.92   39.25 2434.23 45397.71 48512.94 50212.43 51898.92 54963.14\n##         n_eff Rhat\n## alpha    3148    1\n## beta_h   2999    1\n## tau_h    2425    1\n## beta_c   2330    1\n## tau_c    2171    1\n## sigma    3899    1\n## theta    4247    1\n## savings  3846    1\n## \n## Samples were drawn using NUTS(diag_e) at Tue Jun 20 14:21:00 2023.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\ntraceplot(fit, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"lp__\"))\npairs(fit, pars = c(\"alpha\", \"beta_h\", \"tau_h\", \"beta_c\", \"tau_c\", \"sigma\", \"theta\"))## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter\n\n## Warning in par(usr): argument 1 does not name a graphical parameter"},{"path":"optCautocorr.html","id":"model-checking-1","chapter":"5 Tutorial 3: correlated residuals","heading":"5.4.2 Model checking","text":"model checking metrics usual: coefficient determination \\(R^2\\), CV(RMSE), F-statistic… calculate mean prediction rather full posterior distribution.\\(R^2\\) increased 0.66 0.78 since added \\(\\mathrm{MA}(1)\\) regression coefficient, CV(RMSE) decreased. suggests model better explains data’s variance.","code":"\nla <- rstan::extract(fit, permuted = TRUE)\npredict.mean <- colMeans(la$y_pre_pred)\n\nresiduals <- predict.mean - df.pre.day$E      # residuals\nssres <- sum(residuals^2)                     # sum of squared residuals\nsstot <- sum((df.pre.day$E-mean(df.pre.day$E))^2) # total sum of squares\n\nR2 <- 1 - ssres / sstot   # coefficient of determination\nCVRMSE <- sqrt(ssres / nrow(df.pre.day)) / mean(df.pre.day$E)\n\nprint(paste(\"R2 =\", R2))\nprint(paste(\"CV(RMSE) =\", CVRMSE))## [1] \"R2 = 0.776975544980678\"\n## [1] \"CV(RMSE) = 0.0795665214087723\""},{"path":"optCautocorr.html","id":"savings","chapter":"5 Tutorial 3: correlated residuals","heading":"5.4.3 Savings","text":"choose skip prediction plot go straight savings estimate confidence bounds:Compared results tutorial 2, mean estimated savings similar, uncertainty 10% larger.","code":"\nquantile(la$savings, probs=c(0.025, 0.1, 0.5, 0.9, 0.975))##     2.5%      10%      50%      90%    97.5% \n## 45397.71 47105.36 50212.43 53279.24 54963.14"},{"path":"optCautocorr.html","id":"residuals","chapter":"5 Tutorial 3: correlated residuals","heading":"5.4.4 Residuals","text":"whole point tutorial, compared previous one, reduce autocorrelation prediction residuals, sign biased models unreliable inferences. succeded?\nFigure 5.1: Autocorrelation function prediction residuals\nEvery vertical line graph shows correlation coefficient values series (residuals) values certain lag.lag-1 ACF significantly reduced. cause correlation consecutive residuals solved, model now “knows” something unexplained causing : predictions made uncertain way aknowledge .can zoom lag-1 autocorrelation plotting residuals versus previous value:\nFigure 5.2: Correlation consecutive residuals\nlonger visible trend scatter plot.However, can notice Fig. @(fig:tuto3corr1) autocorrelation remains every 5 lags. Remember since filtered week ends, week data comprises 5 measurements. Therefore, looks like weekly pattern still properly captured.\nFigure 5.3: Correlation residuals lag-5\ntrend . need define new model includes regression terms lag-1 lag-5 errors.","code":"\nacf(residuals)\nggplot() +\n  geom_point(mapping = aes(x=residuals, y=lag(residuals, n=1, default=0)))\nggplot() +\n  geom_point(mapping = aes(x=residuals, y=lag(residuals, n=5, default=0)))"},{"path":"optCautocorr.html","id":"new-model-ma5","chapter":"5 Tutorial 3: correlated residuals","heading":"5.5 New model: MA(5)","text":"","code":""},{"path":"optCautocorr.html","id":"even-more-uncertainty","chapter":"5 Tutorial 3: correlated residuals","heading":"5.5.1 Even more uncertainty","text":"Fig. @(fig:tuto3corr1) suggests MA(1) change-point model still shows autocorrelation fitting, especially lags 2 5. therefore tempted extend lag-5 residuals predictors outcome variable \\(y\\):\\[\\begin{align}\ny_n & = \\alpha + \\beta_{h}(\\tau_{h}-x_n)^+ + \\beta_{c}(x_n-\\tau_{c})^+ + \\theta_1 \\varepsilon_{n-1} + \\theta_5 \\varepsilon_{n-5} + \\varepsilon_n \\tag{5.9} \\\\\n\\varepsilon_n & \\sim \\mathrm{normal}\\left(0, \\sigma\\right) \\tag{5.10}\n\\end{align}\\]already stated, , making physical model \\(f(x)=\\alpha + \\beta_{h}(\\tau_{h}-x)^+ + \\beta_{c}(x-\\tau_{c})^+\\) complex. accounting fact completely explain data : \\(y\\) explained \\(f\\) plus something else. can expect inferences model uncertain, reliable.call model MA(5) fifth order moving average model, using residuals lag 5; lags 1 5. Stan code model separate file changepoint_ma15.stan, similar previous model, MA(1).MA(5) model uses data MA(1) model just fitted, :may notice differences previous time called stan() function. MA(5) turned much less identifiable expected, precautions required reach convergence chains.Priors included model itselfcontrol = list(max_treedepth = 12) increases maximum tree depth. mostly efficiency measure.seed lets us specify seed MCMC algorithm. used many attempts converge (non-matching chains), want able show reproducible results page.","code":"\n# Fitting the model\nfit15 <- stan(\n  file = 'models/changepoint_ma15.stan',  # Stan program\n  data = model_data,        # named list of data\n  chains = 4,               # number of Markov chains\n  warmup = 3000,            # number of warmup iterations per chain\n  iter = 4000,              # total number of iterations per chain\n  cores = 2,                # number of cores (could use one per chain)\n  refresh = 0,              # progress not shown\n  control = list(max_treedepth = 12),\n  seed = 5678,\n)"},{"path":"optCautocorr.html","id":"results-2","chapter":"5 Tutorial 3: correlated residuals","heading":"5.5.2 Results","text":"fitting, let’s find new model reliable previous ones. first model checking metric \\(R^2\\) coefficient:\\(R^2\\) now 0.84, significantly better original change-point model (0.66) even MA(1) model (0.78).Now let’s look autocorrelation function residuals:95% confidence interval savings now 50% larger MA(1) model, nearly 80% larger original change-point model. may sound like bad news, nuanced: first model completely reassuring model checking metrics. can much confident real value savings lies within bounds.","code":"\nla15 <- rstan::extract(fit15, permuted = TRUE) # all posterior variables\npredict.mean <- colMeans(la15$y_pre_pred)     # mean prediction\nresiduals <- predict.mean - df.pre.day$E      # residuals\nssres <- sum(residuals^2)                     # sum of squared residuals\nsstot <- sum((df.pre.day$E-mean(df.pre.day$E))^2) # total sum of squares\nR2 <- 1 - ssres / sstot   # coefficient of determination\nprint(paste(\"R2 =\", R2))## [1] \"R2 = 0.835995817169064\"\nacf(residuals)\nquantile(la15$savings, probs=c(0.025, 0.1, 0.5, 0.9, 0.975))##     2.5%      10%      50%      90%    97.5% \n## 39631.43 42487.19 47822.92 52811.51 55433.41"},{"path":"optDbasics.html","id":"optDbasics","chapter":"6 Option D basics","heading":"6 Option D basics","text":"guide extend IPMVP Option D near future. page still construction.","code":""},{"path":"bayesian-calibration.html","id":"bayesian-calibration","chapter":"7 Bayesian calibration","heading":"7 Bayesian calibration","text":"literature principles “bayesian calibration”, Option D can done bayesically.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
